<HTML>
<HEAD>
<TITLE>Дрейфус Х. Чего не могут вычислительные машины Глава 2 -4</TITLE>
<META NAME="keywords" CONTENT="Чего не могут вычислительные машины.">
<META NAME="description" CONTENT="Чего не могут вычислительные машины. 
(Дрейфус Х.)">
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=windows-1251">
<STYLE>
P {
	FONT-SIZE: 12pt;  TEXT-ALIGN: justify; 
}
BODY {
	MARGIN: 40px 30px
}
P.Page {
	FONT-WEIGHT: bold; FONT-SIZE: 10pt; MARGIN: 0cm 0cm 0pt; COLOR: #666699; FONT-FAMILY: "Times New Roman"
} 
</STYLE>

</HEAD>

<BODY>
<center>

<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" WIDTH="80%">
<TR>
<TD>
<center>
<H2>Х. Дрейфус "Чего не могут вычислительные машины"</H2>
<A href="ch1.htm#ogl">К оглавлению</A>
</center>
<HR>
<a name="12">
<B><P>Глава 2. ВТОРОЙ ЭТАП</P>
<P>(1962-1967)</P>
<P>ПРОЦЕССЫ ПЕРЕРАБОТКИ СЕМАНТИЧЕСКОЙ ИНФОРМАЦИИ</P></B>
<P>
Для того чтобы определить место первого этапа в общей картине развития и дать 
представление о том, что ожидалось и что было сделано на втором этапе, начнем с 
того, что приведем цитату из краткого обзора истории работ по "машинному 
интеллекту", произведенного М.Минским:
</P>
<P>
"В начале 50-х годов, когда универсальные вычислительные машины стали доступным 
средством научных изысканий, кибернетика распалась... на три главных 
направления, В исследованиях, происходивших в рамках первого из них, 
продолжались поиски простых фундаментальных принципов. Целью этих поисков стало 
отыскание того, что мы могли бы назвать "минимальными самоорганизующимися 
системами". Для этого подхода характерна установка на построение большого 
набора, как правило, однотипных элементов, который, будучи организован в 
некоторую структуру с очень слабыми ограничениями и погружен в соответствующую 
внешнюю среду, начинает вести себя "адаптивным" образом. В конечном счете можно 
полагать, что разумное поведение возникает на основе эволюции такого рода 
систем"*.
</P>
<P>
Поскольку исследователи, до сих пор придерживающиеся этого направления (его 
иногда называют кибернетикой) 42, не создали ничего интересного - несмотря на 
то, что выразитель соответствующих идей Ф.Розенблат является автором самых 
фантастических предсказаний и заявлений**,- здесь мы не будем касаться их работ.
</P>
<P>
* М. Minsky. Introduction.-In: M. Minsky (ed). Semantic Information 
Processing, Cambridge, p, 6-7.	
</P>
<P>
** Например, следующее сообщение, помещенное в "Chicago Tribune" от 7 июня 
1963г.: "Вчера один из сотрудников Корнелльского университета, специалист по 
обучающимся машинам, сообщил о разработке машины, которая может выдавать на 
печать текст любого воспринимаемого ею выступления на уровне 
секретаря-машинистки. Ожидается, что к осени (Sic! - Х.Д-) устройство будет 
готово. Ф. Розенблат, руководитель проводимых в Корнелльском университете 
разработок по моделированию познающих систем, сказал, что эта машина станет 
самым крупным "мыслящим" устройством, известным на сегодняшний день, Розенблат 
выступил с этим заявлением на одном из совещаний по обучающимся машинам, 
которое проходило в Технологическом институте Северо-западного университета".
</P>
<P>
В своей математической работе "Перцептроны" (Cambridge, Mass., M.I.T. Press, 
1969) M. Минский и С. Пейперт гораздо менее оптимистически оценивают 
исследования в области перцептронов: "Перцептроны широко рекламировались как 
машины для "распознавания образов" или "обу-
</P>
<P class=Page>79</P>
<P>
"Второе важное направление включает в себя попытки построения действующих 
моделей поведения человека-., при этом требуется, чтобы поведение машины было 
адекватно поведению испытуемого..."*
</P>
<P>
"Хороший обзор результатов, полученных в этой области до 1961 г., дается в 
книге "Вычислительные машины и мышление", редакторы которой - Э.Фейгенбаум и 
Дж.Фельдман - выполняли свою диссертационную работу в исследовательской группе 
института Карнеги"**,
</P>
<P>
Имеются в виду именно те исследования в области моделирования процесса 
познания, проводимые Ньюэллом и Саймоном, критике которых была посвящена гл.1. 
Минский также критически относится к этим работам; в частности, в статье, 
написанной им где-то в конце первого этапа, он говорит;
</P>
<P>
"Методы, дающие неплохие результаты при решении простых задач, с большим трудом 
удается распространить на сложные задачи. Дальнейшее их развитие потребует 
реализации новых идей, так как в настоящее время мы вплотную сталкиваемся с 
очень трудными задачами"***.
</P>
<P>
Так звучит в устах Минского признание уже отмеченного нами застоя. Тем не менее 
Минский вместе со своей группой в Массачусетс ком технологическом институте 
берется выдвинуть новые идеи и реализовать их:
</P>
<P>
"Третье направление, которое мы будем называть искусственным интеллектом 
представляет собой попытку построения "разумных машин" без претензии на 
создание простейших биологических или "гуманоидных" систем.   Исследователи, 
работающие в этом направлении, считают разра-
</P>
<P>
чающиеся машины" и как таковые обсуждались в многочисленных книгах, журнальных 
статьях и объемистых "отчетах". Большая часть этих творений», лишена научной 
ценности" [М, Минский, С. Пейперт. Перцептроны. М., 1971, с. 10); «схемы 
Розенблата [1958] быстро укоренились, и в скором времени буквально сотни групп, 
больших и малых, стали проводить опыты с этой моделью под видом либо 
"обучающейся машины", либо "адаптивной", то есть "самоорганизующейся" системы, 
либо систем! "автоматического управления".
</P>
<P>
Результаты этих сотен проектов и опытов, как правило, разочаровывали, а 
объяснения не убеждали. Машины обычно хорошо еели себя на очень простых 
задачах, но весьма быстро сдавали позиции, как только порученные им задания 
становились сложнее» (там же, с. 25) .
</P>
<P>
В свете этих практических трудностей и теоретических ограничений, обрисованных 
Минским и Пейпертом, энтузиазм по поводу ожидающего перцептроны будущего 
представляет собой идеальную иллюстрацию эффекта "обманчивости первого шага"43 
(см. подстрочное примечание на с. 78),   Характерное   выражение   подобная  
 ошибочная   экстраполяция
нашла   в   заявлении Тофлера («Future Shock)), p, 186): "Эксперименты
Фрэнка Розенблата и других доказывают, что машины могут учиться на своих 
ошибках, улучшать свои результаты, а в случае некоторых ограниченных типов 
процесса обучения они в состоянии превзойти человека". Тофлер ничего не говорит 
о том, насколько серьезны эти ограничения.
</P>
<P>
* M.Minsky. Introduction.-In: M. Minsky (ed.) Semantic Information 
Processing, p. 7,
</P>
<P>** Ibid,, p. 8.</P>
<P>
*** M.Minsky. Descriptive Languages and Problem Solving.-In: M.Minsky 
(ed.). Semantic Information Processing, p. 419.
</P>
<P class=Page>80</P>

<P>
ботку самоорганизующихся систем малообещающим или, лучше сказать, 
преждевременным делом. Даже если принять в качестве основной цели простоту 
изначальной организации, не исключено, что потребуется накопление 
предварительного опыта с действующими "разумными системами" (принцип действия 
которых, если нет другого выхода, может быть основан на приемах ad hoc ), 
прежде чем в конце концов удастся построить более экономичные модели"*.
</P>
<P>
Перейдем к рассмотрению этого третьего и сравнительно недавнего направления и 
попытаемся на основе результатов, опубликованных в книге М. Минского "Процессы 
переработки семантической информации", разобраться, что же в действительности 
было сделано. Сам Минский однажды предложил для оценки программ, представленных 
в его книге, пользоваться следующими пятью вопросами:
</P>
<P>1.Почему были выбраны именно данные конкретные задачи?</P>
<P>2.Как работают данные программы?</P>
<P>3.Каковы пределы возможностей программ?</P>
<P>4.Что реально они делают?</P>
<P>5.Как может быть расширена область их применения?</P>
<P>
Если в соответствии с этими вопросами мы проанализируем программы, которые 
Минский считает лучшими из всех написанных с 1962 г., мы увидим, что в отличие 
от работ, выполненных до 1961 г, (когда впечатление "разумности" создавалось в 
основном за счет моделирования простых механических аспектов разумного 
поведения), для предлагаемого подхода характерно следующее: с помощью 
специальных приемов, подбираемых ad hoc, решаются искусно подобранные задачи, 
создающие иллюзию сложной интеллектуальной деятельности. Однако проблемы, 
бывшие камнем преткновения на первом этапе, так и остаются нерешенными. Кроме 
того, мы еще раз убедимся в том, что лишь не допускающая никаких сомнений 
изначальная уверенность таких исследователей, как Минский, дает им возможность 
считать существующую ситуацию обнадеживающей.
</P>
<P>
Рассмотрим эти программы более подробно.
</P>
<a name="12a">
<B><P>I. Анализ программ переработки семантической
информации</P></B>
<P>
Программа, "понимающая английский язык" - программа STUDENT, составленная Д. 
Бобровым.
</P>
<P>
STUDENT- это программа для решения алгебраических задач на составление 
уравнений. Она рассматривается в качестве лучшей из всех пяти программ 
переработки семантической информации, представленных в книге М. Минского. 
Программа Д. Боброва,
</P>
<P>
* М. Мinsky. Introduction.-in: M. Minsкy (ed.). Semantic Information 
Processing, p, 8.
</P>
<P class=Page>81</P>
<P>
говорит Минский -"блестящая демонстрация возможностей использования смысла при 
решении лингвистических задач"*. И действительно. Минский посвящает этой 
программе значительную часть своей статьи в журнале "Scientific American", где 
считает возможным утверждать даже, будто эта программа позволяет машине 
"понимать английский язык"**.
</P>
<P>
Поскольку эту программу на сегодняшний день считают наилучшей, начнем с 
детального ее анализа в соответствии с предложенными М. Минским пятью вопросами.
</P>
<P>
Почему были выбраны именно данные конкретные задачи?
</P>
<P>
Саги Д. Бобров говорит:
</P>
<P>
"При построении системы, отвечающей на вопросы, многие задачи значительно 
упрощаются, если ограничивать их контексты"***.
</P>
<P>
Более того:
</P>
<P>
"Существует несколько причин, в связи с которыми именно алгебраические задачи 
на составление уравнений были выбраны в качестве материала для развития 
методов, позволяющих машинной системе для решения задач воспринимать 
информацию, выраженную на естественном языке. Во-первых, уже существует хорошая 
структура данных, дающая возможность заносить в память машины сведения, 
необходимые для ответа на вопросы, которые относятся к контексту алгебраических 
задач, а именно алгебраические уравнения"****.
</P>
<P>
Существенно, что выбор данной задачи связан с тем, что ограниченность контекста 
облегчает ее решение. Вся важность этого ограничения станет очевидна только 
после рассмотрения следующих двух вопросов.
</P>
<P>
Как работает данная программа?
</P>
<P>
Программам попросту разбивает предложения, фигурирующие в тексте задачи, на 
отдельные блоки, пользуясь для этого такими ориентирами, как слова "больше 
чем", "равно", "во столько-то раз" и т. д.; затем, используя переменные х и у, 
она приравнивает друг к другу полученные куски предложений и пытается добиться 
одновременного выполнения получившегося равенства. Если полученные уравнения 
решить не удается, программа переходит к другим правилам разбиения данных 
предложений и предпринимает новую попытку решения. Вся эта схема может работать 
только потому, что выполняется некоторое ограничение (отсутствующее в задачах 
на понимание обычной разговорной речи), благодаря которому тот или иной способ 
замены кусков предложений переменными приводит к уравнениям, имеющим решение. 
По выражению Минского, "некоторая возможность синтакси-
</P>
<P>* Ibid, р.5.</P>
<P>
** См.: М. Минский, Искусственный разум. В кн.: Информация М., 1968, с. 210.
</P>
<P>
*** D. Вobrow. Natural Language Input for a Computer Problem Solving 
Sistem.ln: M.Minsky (ed). Semantic Information Processing p. 135 </P>
<P>**** Ibid,, p. 137.
</P>
<P class=Page>82</P>
<P>
ческой неоднозначности на входе устраняется, исходя из общего принципа 
алгебраической непротиворечивости"*.
</P>
<P>
Существует также еще одна особенность задач на составление уравнений, благодаря 
которой выбор пал именно на них.
</P>
<P>
"В естественном языке неоднозначность возникает не только в связи с тем, что 
слова в предложении могут быть по-разному структурированы за счет разбиения на 
группы различными способами, но также в связи с тем, что каждому отдельному 
слову можно приписать разные значении, В программе STUDENT положение более или 
менее облегчается тем, что выполняется такое сильное семантическое ограничение, 
при котором рассматриваемые предложения выражают алгебраические соотношения 
между обозначаемыми сущностями"**.
</P>
<P>
Каковы возможности этой программы?
</P>
<P>
Использование алгебраического контекста, с одной стороны, несет с собой 
определенные преимущества; с другой же стороны, однако, оно существенно 
ограничивает область применения программы. Подобное "сильное ограничение" 
исключает из рассмотрения как раз тот аспект естественного языка (а именно его 
неоднозначность), который усложняет задачу машинной обработки естественного 
языка и, быть может, делает ее вообще неразрешимой. Подобные программы 
настолько далеки от семантического понимания как такового, что, как признает 
сам Бобров, "фраза the number of times I went to the movies, которая должна 
была бы интерпретироваться как последовательность, имеющая характер переменной, 
будет неправильно истолкована программой как результат применения оператора к 
двум переменным- number of и I went to the movies,- поскольку times всегда 
рассматривается как знак операции"***.
</P>
<P>
Что же, собственно, было достигнуто?
</P>
<P>
Д. Бобров довольно осторожен. Хотя его работа несколько опрометчиво озаглавлена 
"Программа решения задач на ЭВМ с вводом исходных данных на естественном 
языке", он с самого начала недвусмысленно говорит, что его программа способна 
"воспринимать достаточное, но ограниченное подмножество выражений английского 
языка"****. Затем он добавляет:
</P>
<P>
"В дальнейшем изложении я буду пользоваться фразами типа "программа понимает 
английский". Во всех подобных случаях под "английским" понимается ограниченное 
подмножество выражений английского языка, допустимое на входе обсуждаемой 
программы для вычислительной машины"*****
</P>
<P>
* М. Мinsky. Introduction.-In: M. Minsкy (ed). Semantic Information 
Processing, p. 18.
</P>
<P>** Ibid., p. 20.</P>
<P>*** D. Воbrow. Op. cit., p. 1B345.</P>
<P>
**** D. Bоbrоw. Natural Language Input for a Computer Problem Solving 
Program, MACTR-1, V.Y.T.,abstract of thesis, p. 3 (курсив мой.-Х-Д.).
</P>
<P>
***** D. Bobrow. Natural Language Input for a Computer Problem Solving 
System,-In: M. Minsky (edj. Semantic  Information Processing, p. 135,
</P>
<P class=Page>83</P>
<P>
Достаточно прямолинейное заявление. Автор программы претендует только на то, 
что оправдано ограниченным выбором материала. Он подчеркивает, что "программа 
STUDENT воспринимает слова как символы и ограничивается лишь тем минимумом 
знания слов, который необходим для решения данной
конкретной задачи"*.
</P>
<P>
Другими словами, эта программа воплощает в себе некий минимум семантического 
понимания, Бобров горд тем, что достиг столь многого при минимальных затратах. 
"В основу семантической модели системы STUDENT положено одно отношение 
(равенство) и пять основных арифметических функций**.
</P>
<P>
В равной степени осторожность Боброва проявляется в подчеркивании специфичности 
значения глагола "понимать".
</P>
<P>
Для целей данной работы я воспользовался следующим операциональным определением 
термина "понимание". Вычислительная машина понимает предложение из 
определенного подмножества предложений английского языка, если она воспринимает 
это предложение и отвечает на вопросы, касающиеся информации, в нем 
содержащейся. В этом смысле система STUDENT понимает английский язык"***.
</P>
<P>
В заключение Бобров осторожно пишет: "Я полагаю, что нам далеко еще до 
написания программы, которая могла бы понимать весь английский язык или хотя бы 
его достаточно большую часть. Однако в своей узкой специальной области 
программа STUDENT доказала, что "понимающие" машины могут быть построены"****.
</P>
<P>
Тем не менее в своей статье в журнале "Scientific American" М. Минский говорит, 
что "STUDENT -- понимает английский язык". Что же произошло?
</P>
<P>
Дело в том, что Бобров ставит слово "понимает" в кавычки. Следует все время 
помнить, что "понимает" для него значит просто "отвечает на вопросы, 
относящиеся к некоторой части английского языка, ограниченной контекстом задач 
на составление алгебраических уравнений". При этом он предпочитает говорить 
"понимает", а не "перерабатывает информацию"- Однако невольно возникает 
ощущение, что его программа имеет какое-то отношение к человеческому пониманию. 
Этим и воспользовался Минский: в своей риторической статье он просто опустил 
кавычки.
</P>
<P>Еще более удивительны и чреваты  ошибочными выводами</P>
<P>
* D.Bobrow. Natural Language Input for a Computer Problem Solving System.- In: 
M. Minsky (ed.). Semantic Information Processing, p. 144.
</P>
<P>** Ibid. p. 191.</P>
<P>
*** Ibid,, p. 135, В том смысле, в каком Бобров употребляет слова "понимает" и 
"английский язык", даже машина, которая, будучи снабжена фразой "You are on" 
("Вы включены"), только и может что ответить "Yes" на вопрос "Are you on?", 
уже "понимает английский язык
</P>
<P>
**** Ibid. 194.
</P>
<P class=Page>84</P>
<P>
заявления М.Минского, касающиеся «огромного потенциала обучения» программы Д. 
Боброва:
</P>
<P>
"Обратите внимание на то, как качественно меняется вся работа программы Боброва 
STUDENT после того, как ей скажут, что "расстояние равняется скорости, 
умноженной на время"! Уже этот единичный акт расширения ее опыта дает ей 
возможность решать новый род задач школьной алгебры, а именно физические 
задачи, в которых фигурируют расстояние, скорость и время. Не следует думать, 
что кривая научения всегда должна медленно ползти вверх на фоне тошнотворно 
частых повторений. Очень важно отвыкнуть от взгляда, что обучение есть только 
там, где имеет место этот процесс.
</P>
<P>
В программе Боброва нет никаких специально предусмотренных статистических 
механизмов, так что ей не нужно повторять что-то снова и снова;   ее обучение 
настолько блестяще, что его и не назовешь обучением"*.</P>
<P>
Однако в этом случае нетрудно показать, что процесс, который происходит в 
машине, никак нельзя назвать "пониманием". В машину действительно было введено 
еще одно уравнение, но машина не понимает, что это формула; иначе говоря, 
программа может, конечно, подставить в уравнение d- r-t одно значение 
расстояния, одно значение скорости и одно значение времени, но она ничего не 
понимает, так как не может использовать это уравнение дважды в одной и той же 
задаче, поскольку неспособна решать вопрос о том, какие величины связывают друг 
с другом те или иные уравнения. Как признает Бобров, "в задаче одна и та же 
переменная должна быть представлена одной и той же фразой"**. Итак, обучения не 
произошло.
</P>
<P>
Отбросив кавычки в слове "понимает", а в слове "обучение" сделав их символом 
сверхчеловеческого обучения. Минский переходит в область умозрительных 
рассуждений:
</P>
<P>
"Чтобы машины могли хотя бы улучшить свою работу, существенно необходимо иметь 
в машине элементарное понимание собственного процесса решения задач и некоторую 
способность распознавать улучшение, когда оно найдено. Я не вижу веских причин, 
почему это невозможно для машины. Если заложить в машину модель ее собственной 
работы, она наряду с решением других задач могла бы работать и над задачей 
самосовершенствования..,
</P>
<P>
После того как мы создадим программы, наделяющие машины подлинной способностью 
к самоулучшению, начнется быстро развивающийся процесс в этой области. 
Поскольку машина улучшает и самое себя и собственную модель, мы сумеем увидеть 
все те явления, которые мы связываем с такими понятиями, как "сознание", 
"интуиция" и даже "разум". Трудно сказать, насколько близко мы подошли к этому 
порогу, но когда-нибудь мир переступит через этот порог и ему уже невозможно 
будет остаться прежним"***
</P>
<P>* М. Мinsky.  Introduction.-In: М. Мinsky   (ed). Semantic 
Information Processing, p, 14.</P>
<P>
** D.Bobrow.  Op. cit.-In: M.Minsky  (ed.). Semantic Information Processing, p. 
192.</P>
<P>
*** M. Mинский. Искусственный разум. - В кн.:  Информация,с. 214-215.
</P>
<P class=Page>85</P>
<P>
Однако не так уж трудно, вопреки мнению М. Минского, сказать, насколько близки 
мы к этому порогу. Поскольку считается, что в программе Д. Боброва реализованы 
те зачатки понимания и обучения, на которые рассчитывает Минский, нам остается 
только поставить вопрос: до какой степени могут быть обобщены и расширены 
методы, использованные Бобровым?
</P>
<P>
Это приводит нас к последнему вопросу; каким образом можно распространить 
рассматриваемую программу на более широкие области применения?
</P>
<P>
Здесь уже и Д.Бобров отбрасывает всякую осторожность: вопреки своему прежнему 
замечанию о том, что семантическая модель построена на единственном отношении 
(равенстве) и, следовательно, может составлять и решать уравнения только в тех 
случаях, когда удается использовать некоторое алгебраическое условие, он 
заявляет, что его "семантическая теория словесного общения может послужить 
основой для значительно более общей системы переработки языковых соотношений"*. 
Автореферат своей диссертации Бобров заключает уже знакомой нам вариацией на 
тему "первого шага". "Система STUDENT- это первый шаг к общению с 
вычислительной машиной на естественном языке. Дальнейшая работа над этой 
семантической теорией должна привести к гораздо более тонким и богатым 
системам"**.
</P>
<P>
Со времени этого заявления прошло пять лет, однако никакой более богатой 
возможностями семантической теории не появилось46.Трудно понять, почему 
Д.Бобров и М.Минский, отдавая себе отчет о всех специфических ограничениях, 
соблюдение которых необходимо для нормальной работы данной программы, считают 
тем не менее, что такое обобщение наверняка возможно. Я полагаю, что ни 
оправдать, ни хотя бы объяснить их оптимизм по отношению именно к этому, по 
общему признанию весьма ограниченному, подходу ad hoc нельзя ничем. Что же 
касается их "глобального" оптимизма в отношении того, что некоторый машинный 
подход в данной области обязательно будет реализован, то его истоки можно 
проследить вплоть до фундаментальной метафизической предпосылки, касающейся 
природы языка и разумного поведения человека, согласно которой любое 
упорядоченное поведение человека может быть в принципе формализовано и 
представлено в виде программы для цифровой вычислительной машины (см, гл. 5). 
Этим и объясняется уверенность М.Минского и Д.Боброва, позволяющая им 
расценивать все трудности, возникающие на их пути, как технологические затруд-
</P>
<P>* D.Bobrow. Op.cit.-In: М.Мinsky. (ed.).    Semantic   Information 
Processmg, p. 194.</P>
<P>
** D.Bobrow. Natural Language Input for a Computer Solving Program. Abstract of 
thesis, p, 3.
</P>
<P class=Page>86</P>
<P>
нения, связанные, в частности, с ограниченной емкостью запоминающих устройств 
современных ЭВМ*.
</P>
<P>
Не будь этой предпосылки, частичный успех работы Д.Боброва, которую М.Минский 
объявил наиболее многообещающей из существующих, был бы воспринят как искусный 
трюк, ничего не говорящий ни за, ни против возможности существования машинного 
понимания. Тот факт, что эта работа - лучшее, что сумел создать столь 
незаурядный человек, как Д.Бобров, пробудил бы сомнения в возможности 
достижения рубежа, за которым начинаются самосовершенствующиеся машины.
</P>
<P>
Программа   определения    аналогий, разработанная  Т. Эвансом
</P>
<P>
Вся "коллекция" аргументов М. Минского сделана по одному шаблону: о решении с 
помощью приема ad hoc некоторой ограниченной задачи сначала сообщается с 
некоторой осторож­ностью, а затем это решение трактуется как первый шаг к 
развитию более общих методов. Но все работы, представленные в сборнике М. 
Минского, были закончены к 1964 г., и, хотя с той поры прошло еще семь лет, ни 
одно из прокламированных обобщений так и не было осуществлено.
</P>
<P>
Рассмотрим, к примеру, программу определения аналогий Т.Эвзнса - сложную, умело 
написанную программу для решения задач на обнаружение сходства типа тех, 
которые используются в тестировании интеллекта (рис.). Программа решает крайне 
специфическую задачу, и решает ее на уровне среднего десятиклассника, что, 
учитывая современный уровень таких программ, является выдающимся достижением. 
Что еще более существенно, Эванс отдает себе отчет в том, что эта удачная сама 
по себе работа мало что дает: ее можно признать успешной только в том случае, 
если методы, использованные в ней, допускают какое-то обобщение. Но в отличие 
от Д. Боброва он не удовлетворяется утверждением, что такое обобщение возможно- 
В заключении к своей работе он пытается набросать в общих чертах такое 
обобщение и описать те преимущества, которые при этом получат программы для 
решения задач (типа GPS) и распознавания образов:
</P>
<P>
* В статье, помещенной в журнале "Scientific American", М. Минский ставит 
вопрос: "Почему машины не более разумны, чем это есть на самом деле?" - и 
отвечает: "До настоящего времени были весьма ограничены ресурсы в людях, 
времени и сами возможности вычислительных машин. Некоторые наиболее тщательно 
продуманные и серьезные попытки разработки разумных машин уже приближаются к 
поставленным частным целям...; другие исследован ив были ограничены 
возможностями оперативной памяти вычислительной машины; третьи столкнулись с 
трудностями программирования" (М. Минский, Искусственный разум, - В кн.: 
Информация, с. 213-214) .
</P>
<P class=Page>87</P>
<P>
«На последних страницах этой главы мы опишем процесс "распознавания образов", 
главные идеи которого основываются на описанном выше понятии аналогии. 
Предлагаемый подход претендует на некоторые преимущества, глазным образом за 
счет того, что вводятся более мощные и более общие схемы описаний для 
рассматриваемых "объектов"».
</P>
<P>
"GPS трактует составные части некоторого данного объекта с помощью организации 
его в терминах целей и подцелей. Тем самым GPS уходит от рассмотрения сложных 
структур на каждом конкретном уровне путем разложения их на более мелкие 
структуры, связанные с подцелями. Таким образом, GPS никогда не воспринимает 
отдельную сложную структуру как таковую; когда какая-либо подструктура 
рассматривается на более глубоком уровне подцелей, она находится "вне 
контекста" в том смысле, что отсутствует необходимая информация о том, что даст 
достижение этой подцели для продвижения к цели более высокого уровня. Ньюэлл 
обсуждает одну из таких "бесконтекстных" задач и делает несколько довольно 
безуспешных попыток ее решения. Описанный нами в общих чертах механизм 
представляет собой систему распознавания образов, которая в состоянии 
воспринимать "глобальный" аспект задачи и в то же время имеет доступ ко всей ее 
структуре. "Глобальное" управление такого рода может оказаться полезным для 
GPS, давая возможность экономить время (поскольку при существующем варианте 
программы много времени тра­тится на выдвижение и достижение подцелей, не 
ведущих к целям самого высокого или близкого к нему уровня) . Уже одно это 
будет большим шагом вперед"**.
</P>
<P>
Т.Эванс выдвигает также некоторые предложения, касающиеся обучения:
</P>
<P>
* Th. Evans. A Program for the Solution of a Class of Geometnc-Analocy 
Intelligence Test Question.- In: M.M i n s k у (ed.). Semantic Information 
Processing, p.346-347.
</P>
<P>
** Ibid., p. 349.
</P>
<P class=Page>88</P>
<P>
"Разумеется, изучение этих проблем в относительно хорошо разработанной области 
языков со структурой непосредственных составляющих^ представляет собой 
естественный шаг вперед по направлению к созданию настоящего машинного 
"обучения обобщению"; кроме того, решение этих задач откроет путь к 
исследованию проблемы моделирования обучения в случае более сложно описываемых 
языков. Поскольку правила преобразования могут быть сами выражены в терминах 
структуры непосредственных составляющих, одна из интересных возможностей 
состоит в том, чтобы применить совокупный аппарат "структура непосредственных 
составляющих плюс GPS" для улучшения собственного набора правил 
преобразования"*.
</P>
<P>
Т.Эванс понимает, что "это, по-видимому, крайне трудная задача"**. Скорее 
всего, так оно и оказалось, поскольку с момента завершения в 1963 г. его работы 
над этим проектом о нем больше не было опубликовано ни слова. Как мы видели, 
Ньюэлл также забросил свою GPS, а распознающие программы, по словам М.Идена, в 
1968 г. основывались по-прежнему на приемах ad hoc. Отсюда вновь следует 
знакомый вопрос: почему М.Минский и Т.Эванс так уверены, что метод ad hoc, 
приведший к решению этой специфической и довольно сложной задачи отыскания 
аналогий, может быть обобщен? Некоторый намек на причины этой уверенности можно 
найти в довольно неожиданном сравнении, которое проводит Минский между 
программой Эванса и человеческим способом решения задач, основанном на 
аналогии. Вопреки своим обычным заверениям о том, что ИИ не имеет отношения к 
моделированию познания, Минский дает следующее "менталистское" описание работы 
программы Эванса:
</P>
<P>
"Для изложения сущности этой работы лучше всего описать данную программу в 
менталистских терминах. Если задан некоторый набор фигур, то программа строит 
набор гипотез или теорий следующим образом:
</P>
<P>
1. Основываясь на описаниях    D(A) и D(B)   фигур    А и В   (см.рис.2,
- Х-ДЛ, можно выбрать много путей преобразования D(A) в D(B); выбери
ОДИН ИЗ НИХ,
</P>
<P>
2. Существует также много путей установления соответствия между
частями фигуры А и частями фигуры С; каждое такое соответствие может
стать основой некоторого отношения того типа, о котором шла речь в п.1,
но на сей раз связывающего фигуру С с какими-то другими фигурами,
</P>
<P>
3. Маловероятно, что какое-нибудь из отношений, найденных в п.2,
окажется полностью применимым к какой-нибудь фигуре-ответу.   (Если
оно окажется таковым, то соответствующая фигура и есть результат
работы    программы.)   Для   каждой   фигуры-ответа   каждое  отношение
должно быть "ослаблено" (то есть обобщено) ровно настолько, насколько
это нужно для того, чтобы оно оказалось применимо к данной фигуре.
</P>
<P>
4. И наконец, программа учитывает степень ослабления каждого отношения.   Она 
выбирает то из отношений,  которое требует наименьшего
изменения и выдает в качестве результата соответствующую фигуру из
множества фигур-ответов.
</P>
<P>
Выбирая гипотезу, связанную с минимальным "ослаблением" исходного 
преобразования А ~^ В, программа тем самым отдает предпочтение
</P>
<P>
* Ibid., p. 350. <BR> ** Ibid. </P>
<P class=Page>89</P>
<P>
тому объяснению, в котором заключено больше информации, общей для отношений А~> 
В и С^* D. Подробности правил выбора на этапах 1, 2, 3, 4 и составляют, в 
сущности, предложенную Эвансом теорию человеческого поведения в подобных 
ситуациях, Я совершенно убежден в том, что любое рассуждение по аналогии 
включает в себя нечто, имеющее именно такой общий характер"*.
</P>
<P>
В статье, опубликованной в журнале "Scientific American", М.Минский 
сформулировал это "нечто" более четко: "Я убежден, что все виды рассуждения по 
методу аналогии повинуются этим правилам"**. Это та же самая предпосылка, 
которая, как мы видели, лежит в основе работ Ньюэлла и Саймона в области 
моделирования процессов познания. При описании процедуры решения задачи Т.Эванс 
фактически повторяет Ньюэлла:
</P>
<P>
"Эти программы, в сущности, похожи. Их работа - процесс не простой, так что мы 
можем сказать, что обе программы действительно решают задачу, а не просто 
осуществляют шаг за шагом те процедуры поиска решения, которые придумал 
программист. Они имеют дело с формализованными задачами, хотя и трудными, но с 
"хорошей структурой". Программы строятся на единой системе понятий: они находят 
комбинаторную интерпретацию задачи, сводя ее к поиску правильной 
последовательности операций среди множества всех возможных последовательностей. 
Все программы порождают то или иное дерево возможностей и шаг за шагом 
исследуют все допустимые последовательности. Множество всех последовательностей 
слишком необъятно, его нельзя построить и просмотреть in toto, поэтому для 
сокращении числа возможностей до разумных пределов, поддающихся машинной 
обработке, используются различные ухищрения, называемые эвристиками".
</P>
<P>
В заключение Т.Эванс пишет:
</P>
<P>
"Программа геометрических аналогий также подпадает под это описание. Говоря 
очень кратко, при рассмотрении задач такого типа программа использует различные 
эвристики для выбора (за разумный срок) "адекватного" правила из очень широкого 
класса допустимых
</P>
<P>
Можно с уверенностью сказать, что если бы человек решал задачи поиска аналогий 
именно таким образом, то были бы все основании надеяться на улучшение и 
обобщение программы Эванса, поскольку человек, разумеется, далеко превосходит 
уровень, демонстрируемый существующими программами. Однако, как и в случае GPS, 
ничто не говорит в пользу того, что человек действует именно таким образом, а 
данные эмпирической психологии свидетельствуют как раз об обратном.
</P>
<P>
Р.Арнхейм, профессор психологии Гарвардского университета, анализируя работу 
Эванса, указал на иной подход, которым пользуется человек, решая задачи такого 
рода. Слова Арнхейма стоят того, чтобы привести их полностью:
</P>
<P>
* М.Мinsky - Introduction.-In: M.Minsky (ed). Semantic Information 
Processing, p.16 (курсив мой.-X.Д.)
</P>
<P>
** М.Минский. Искусственный разум. - В кн.: Информация, с. 206.
</P>
<P>
*** Th.Evans. Op.cit.-In: M. Minsky (ed.) Semantic Information Processing, 
p. 280 
</P>
<P class=Page>90</P>
<P>
“Что происходит, когда человек сталкивается с фигурой, подобной той, которая 
изображена на рис. [2]? Реакция будет несколько меняться от человека к 
человеку, поскольку нет никакого конкретного контекста, способствующего 
концентрации внимания на тех или иных специфических структурных признаках. 
Однако в общем и целом испытуемый, вероятнее всего, заметит своего рода 
вертикальную организацию, состоящую из двух частей, верхняя из которых сложнее 
и больше по величине, чем нижняя48
</P>
<P>
он может заметить также различия в контурах. Другими словами, он воспримет 
качественные характеристики конфигурации, относительные величины и очертания, в 
то время как большинство метрических свойств, с учета которых должно начинаться 
восприятие образа вычислительной машиной, а именно абсолютные размеры и те или 
иные длины и расстояния, характеризующие данную конкретную фигуру, он вряд ли 
заметит. Если попросить испытуемых нарисовать фигуру, которую они воспринимают, 
то выяснится, что они обращают внимание на топологические особенности и 
пренебрегают точными размерами.
</P>
<P>
Если теперь испытуемый столкнется с сочетанием фигур Аи В, опыт его резко 
расширится и обогатится. Сначала у него появится смутное ощущение сходства 
между совершенно различными как будто изображениями. Конструкция, состоящая из 
двух данных фигур, в целом может показаться несоединимой, иррациональной, 
непостижимой. Налицо две вертикальные организации, сочетающиеся в своего рода 
симметрии, которая разрушается отношениями по диагонали между двумя большими 
"заполненными" кругами и двумя маленькими "незаполненными" фигурками. 
Многообразие структурных характеристик никак не складывается в единое, 
устойчивое и доступное пониманию целое. Не исключено, однако, что испытуемый 
внезапно уловит, что четыре меньших фигуры - два равных кружка вверху и два 
равных квадрата внизу - составляют вместе простую прямоугольную структуру. Как 
только эта структура станет доминирующим мотивом или организующей основой 
целого, остальные фигурки-два больших круга - добавятся к основному образу в 
качестве второстепенных "диагональных украшений". Иерархия структур 
установлена. Теперь конструкция из двух фигур устойчива, обозрима, доступна 
пониманию и потому готова к сравнению с другими фигурами. Первый акт поиска 
решения задачи произошел.
</P>
<P>
Когда после этого человек обратится к фигуре С, то новое в ней для него с 
самого начала будет определяться опытом, накопленным при рассмотрении фигур А и 
6. Будучи сравниваема с фигурой А, фигура С обнаруживает аналогичную 
вертикальную структуру, отличающуюся от структуры А по существу второстепенным 
различием контуров фигурок. «Фамильное» сходство обеих фигур достаточно велико, 
и отношения между ними устанавливаются просто. Если же теперь С сопоставить с 
D-], то их сходство кажется избыточным, симметрия слишком совершенной. 
Сравнение с D2, напротив, дает слишком малое сходство. Если отношение между А и 
В было установлено правильно, то D3 сразу распознается как подходящая к С пара 
- недостающий четвертый элемент аналогии.
</P>
<P>
Этот пример из области перцептивного решения задач включает все характеристики 
подлинного мышления: проблемную ситуацию, продуктивный поиск, надежды и 
догадки, частичные решения, неприятное ощущение противоречия, внезапное 
озарение, ведущее к окончательному решению, адекватность которого очевидна, 
структурные преобразования, возникающие под давлением изменения ситуации в 
целом, обнаружение элементов сходства между различными образами. Все это, 
вместе взятое, представляет собой в небольшом масштабе живой опыт, достойный 
существа, которому дарован разум. Когда решение наконец найдено, мы ощущаем 
спад напряжения, удовлетворение, покой.
</P>
<P>
В вычислительной машине все происходит иначе, и не потому, что она не обладает 
сознанием, а потому, что принцип ее действия в корне иной. Мы
</P>
<P class=Page>91</P>
<P>
поражаемся, когда узнаем, что для того, чтобы научить машину решить задачу по 
аналогии, экспериментатору "пришлось разработать, пожалуй, одну из самых 
сложных из всех когда-либо написанных программ". Дли нас эта задача не сложна - 
она доступна начинающим студентам. Причина такого различия в том, что подобные 
процессы требуют рассмотрения топологических отношений, а это влечет за собой 
отбрасывание отношений чисто метрических. Мозг приводится в движение именно 
такими "топографическими" признаками, так как они дают нам информацию о 
типовых характеристиках вещей, а не об их конкретных количественных 
характе­ристиках"*
</P>
<P>
Как и в шахматах, глобальное перцептивное разбиение на группы обязательно 
предшествует управляемому правилами перебору - единственному виду деятельности, 
доступному машине. Как пишет Р.Арнхейм, "топология была открыта перцептивной 
мощью мозга и рассчитана на перцептивные, а не арифметические его 
возможности"**.
</P>
<P>
По-видимому, Минский и Эванс полагают, что человек находит аналогии с помощью 
правил преобразования, поскольку прогресс в развитии ИИ возможен только в 
предположении, что человек решает задачи именно таким образом. Но это 
рассуждение заведомо порочно, поскольку нельзя основывать свой оптимизм на 
гипотезе, которая в свою очередь подтверждается только тем фактом, что, окажись 
она верной, оптимизм ее сторонников был бы оправдан.
</P>
<P>
Программа организации семантической памяти, составленная Р. Кеиллианом
</P>
<P>
Последняя из рассматриваемых нами программ самая интересная, так как она 
наиболее обща и наименее претенциозна - по крайней мере ее автор (он работает 
под руководством Г.Саймона, а не М. Минского)   не делает никаких огульных 
заявлений и
обещаний***. Это программа подтверждает общее правило оценки качества 
эвристических программ (вспомним сдержанность А. Сэмюзля, когда он говорит о 
своей программе, и ее результативность, с одной стороны, и претенциозность Г. 
Саймона и X. Гелернтера при очень скромных успехах - с другой), которое 
заключается в следующем: значимость программы часто находится в обратной 
зависимости от обещаний и рекламных заявлений ее авторов.
</P>
<P>
* F.Arnheim. Intelligence Simulated. -"Midway", University of Chicago, 
June 1967, p.85-87. <BR>** Ibid
</P>
<P>
*** В отличие от М. Минского Г. Саймон, по-видимому, не требует от своих 
учеников публичного обета верности, хотя сам принадлежит к числу "верующих".
</P>
<P class=Page>92</P>
<P>
Р.Квиллиан, как и Д.Бобров, занимается моделированием явления понимания 
естественного языка, но в отличие от Боброва и Минского он отдает себе отчет в 
том, что к этой задаче нет смысла подходить с позиции поиска решения с помощью 
приемов ad hoc.
</P>
<P>
"Прежде всего, мы полагаем, что авторы теорий переработки информации или 
машинных моделей, если они хотят добиться успеха, не должны игнорировать 
семантику или устранять ее, как это до сих пор имеет место в большинстве 
программ по переработке информации, заданной на естественном языке. Неважно, 
что именно по замыслу автора должна делать программа - производить 
грамматический анализ предложения, переводить с одного языка на другой или 
отвечать на вопросы, задаваемые на естественном языке,- если в ней не 
учитываются семантические характеристики, причем изначально и достаточно часто, 
то, я думаю, у нее нет шансов достичь уровня человека"*.
</P>
<P>
Предприняв обзор всех имеющихся в этой области работ, включая работу Д. 
Боброва,?. Квиллиан пишет:
</P>
<P>
"Программы, подобные программе Боброва, в состоянии составлять уравнения, 
соответствующие некоторым текстовым алгебраическим зада­чам, с помощью почти 
полностью "синтаксической" процедуры. ...Однако если попытаться расширить ту 
часть языка, которая доступна такой программе, то неизбежно придется вводить в 
нее все большее число семантических фактов"**.
</P>
<P>
В заключение Р.Квиллиан говорит:
</P>
<P>
"...вопрос о том, что должно храниться в общей долговременной памяти, подобной 
памяти человека, как должна записываться в ней информация, как память должна 
быть организована, в предшествующих моделирующих программах не был рассмотрен 
во всей его общности... Дальнейшее развитие моделирования решения задач, 
моделирования игр, а также речевого поведения, несомненно, потребует создания 
программ, организующих большие массивы памяти и взаимодействующих с ними"***.
</P>
<P>
Затем Квиллиан переходит к описанию своей сложной эвристической программы, 
обеспечивающей занесение в память и извлечение из нее значений слов и "всего 
того, что можно выразить в языке, почувствовать в восприятии или каким-либо 
иным путем постигнуть и запомнить"****, - программы, организующей содержание 
памяти в виде одной "огромной, взаимосвязанной сети"*****- По предположению 
Квиллиана, в этой программе воплощена "разумная точка зрения на то, как 
организована
</P>
<P>
* R.Quillian. Semantic Memory.- In: М.Мinsky (ed.). Semantic 
Information Processing, p,251.
</P>
<P>
** R. Quillian. Semantic Memory. Bolt, Beranek and Newman, Inc., Paper 
AFCRL-66-189, 1966, October, p. 54. (В сжатом варианте диссертации, приводимом 
в книге под редакцией М. Минского, этого нет.)
</P>
<P>
*** R. Quillian. Op. cit.-In: M. Minsky (ed.). Semantic Information 
Processing, p.219-220.
</P>
<P>**** Ibid., p,221.<P>  *****lbid.,p.222.
</P>
<P class=Page>93</P>
<P>
семантическая информация в мозгу человека"*. Однако никаких доводов в пользу 
разумности этой точки зрения он не приводит, за исключением разве что того 
соображения, что если бы необходимость хранения семантической информации 
возникла перед вычислительной машиной, то предлагаемая программа оказалась бы 
для этого разумной моделью. В действительности человек не осознает того, как он 
проводит сложные процессы занесения в память и извлечения из нее, о которых 
говорит Р. Квиллиан, Однако последнего это мало волнует; он, как и его учитель 
Саймон, всегда может сказать, что эти процессы все же происходят, 
подсознательно,
</P>
<P>
"Хотя процесс кодирования текста, разумеется, не совпадает с тем скрытым от нас 
процессом, который приводит к пониманию текстового материала при обычном 
чтении, все же он... в каком-то смысле является его замедленной и доступной для 
обозрении версией**.
</P>
<P>
Тот факт, что подобная подсознательная переработка информации действительно 
имеет место и, более того, происходит в соответствии с эвристическими 
правилами, отнюдь не очевиден. Мы уже видели, что и в игре в шахматы, и при 
отыскании аналогий решающее значение имеет разбиение объектов на группы, 
основанное на целостном восприятии; очень может быть, что и в данном случае это 
так. Но создается впечатление, что Р. Квиллиан усвоил от Ньюэлла и Саймона 
безоговорочно принимаемое ими допущение, что человек действует по эвристическим 
программам.
</P>
<P>
"Эвристические методы, с помощью которых выбирается единственное конкретное 
осмысление текста, составляют центральную проблему для всякого, кто хочет 
объяснить "понимание"; точно так же эвристические методы, с помощью которых 
выбирается единственный конкретный ход из всех возможных ходов, составляют 
центральную проблему для всякого, кто хочет объяснить процесс игры в 
шахматы"***.
</P>
<P>
Приняв такое допущение, Квиллиан с неизбежностью должен предположить, что идеал 
программы должен состоять в том, чтобы задавать функционирование системы в 
направлении "от частей к целому",
</P>
<P>
"Выбирая задачу, в рамках которой можно было бы работать с моделью памяти, 
естественно начать со способности к пониманию незнакомых предложений- 
По-видимому, разумно предположить, что у человека нет другого пути понимания 
новых предложений, кроме извлечения из памяти хранящейся в ней информации о 
значениях отдельных слов и словосочетаний (и, возможно, небольшого изменения 
э~их значений) с последующим комбинированием значений в целях формирования 
смысла предложения. В
</P>
<P>* Ibid., р. 216.<P>  **Ibid., р. 247.</P>
<P>
*** R. Quillian.  Semantic Memory, Bolt, Beranek and Newman, Inc., Paper 
AFCRb66-189, p. 113.
</P>
<P class=Page>94</P>
<P>
соответствии с этим в нашу задачу входит построение модели хранения
семантических сведений и формулирование правил комбинирования, по которым из 
хранящихся в памяти смыслов слов происходит построение значений предложений"*.
</P>
<P>
Квиллиан также ждет от своей системы многого:
</P>
<P>
"Далее, вполне правдоподобно, что если бы удалось адекватно закодировать и 
вложить в память ЭВМ хотя бы несколько значений слое, а затем формализовать на 
уровне машинной программы работоспособный набор правил их комбинирования, то 
можно было бы слово за словом наращивать запас закодированных значений 
наподобие шнуровки на ботинках; тогда вычислительная машина сама бы "понимала" 
предложения, которые ею построены, и использовала их для формулировки 
определений других слов. А это значит, что если новое, еще не закодированное 
слово может быть определено с помощью предложения, в которое входят только 
слова с уже закодированными значениями, то машина в состоянии построить объект, 
представляющий смысл этого предложения, исходя из уже имеющихся у нее сведений 
и правил комбинирования;объект этот - представитель смысла - и будет тем 
соответствующим предложению кодом, который следует добавить к содержимому в 
памяти в качестве значения нового слова"**.
</P>
<P>
С откровенностью, столь редкой в публикациях на данную тему, Р. Квиллиан 
сообщает также и о своих разочарованиях;
</P>
<P>
"К сожалению, два года работы над данной проблемой показали, что для нынешнего 
уровня знаний эта задача слишком трудна. Процессы, происходящие в мозгу 
человека, когда он "понимает" предложение и включает его смысл в свою память, 
очень сложны, и происходят они практически без участия сознания"***.
</P>
<P>
Масштабы задачи, стоящей перед Р.Квиллианом, станут яснее, если мы заметим, что
</P>
<P>
"определение восьмисот пятидесяти слое вмещает в себя больше информации, чем в 
состоянии вместить магнитные запоминающие устройства современных вычислительных 
машин"****.
</P>
<P>
Эти трудности наводят на мысль, что, быть может, ошибка кроется в самой модели, 
то есть в идее о том, что наше понимание естественного языка включает в себя 
построение структурированного целого из огромного числа точно описанных частей. 
Работа Р. Квиллиана скорее ставит, чем решает вопрос о запоминании этого 
колоссального множества фактов, - вопрос, возникающий в связи с тем, что в 
проводимом анализе отсутствуют перцептивные гештальты. Если структура данных по 
мере добавления новых определений будет расти слишком быстро, то и без того не 
слишком обнадеживающую работу Квиллиана можно считать reductio ad absurdum 
всего машинно-ориентированного
</P>
<P>
* R.Quillian. Semantic Memory.- In: M.Minsky  (ed.).   Semantic 
Information Processing, p,235.  Ibid, p.235.
</P>
<P class=Page>95</P>
<P>
подхода. Прежде чем решить, дает ли работа Квиллиана основание для оптимизма, 
любопытно получить ответ на коренной вопрос: как с увеличением числа элементов 
растет база данных у Квиллиана - линейно или экспоненциально?
</P>
<P>
По поводу этого основного вопроса, как это ни удивительно, можно встретить 
массу обнадеживающих заверений, но мало информации. Программа Квиллиана имеет 
дело только с 50 - 60 словами. М. Минский в сборнике, вышедшем в 1968 г., то 
есть спустя три года после завершения этой программы, вынужден признать, что 
«пока мы еще мало знаем о том, насколько эффективными станут методы Квиллиана 
при использовании более содержательных "банков знаний"»*. И опять о дальнейшем 
развитии сообщений не имеется.
</P>
<a name="12b">
<B><P>II. Значение сегодняшних трудностей</P></B>
<P>
Каковы разумные перспективы? По оценке М. Минского, в настоящее время программа 
Квиллиана содержит несколько сотен фактов, в то время как "для мощного 
интеллекта потребуется миллион фактов"**. Он также признает, что каждая из 
"рассмотренных (в его книге,- ХД) программ лучше всего будет работать при 
условии обеспечения ее только необходимыми фактами, ибо по мере роста массивов 
информации программы безнадежно увязают в массе фактов"***.
</P>
<P>
Если так, то возникает вопрос, существуют ли хотя бы какие-нибудь основания для 
уверенности в том, что эти программы приближают нас к тем "эвристикам высшего 
уровня, управляющим познавательной структурой", которыми, как считает Минский, 
располагает человек? Можно ли согласиться со следующим заявлением Минского, 
сделанным в другой его работе:
</P>
<P>
"При жизни нашего поколения... останется лишь немного интеллектуальных задач, 
которые будут не под силу машинам: проблема создания "искусственного 
интеллекта" будет в основном решена"****.
</P>
<P>
Во всяком случае, труд "Процессы переработки семантической информации" не дает 
оснований для такой уверенности.1 М. Минский, как мы видели, критикует более 
ранние программы за недостаточную общность. "Каждая программа работает только в 
соответствующей специальной области, и стыковать две разные программы 
оказывается совершенно невозможно"*****. Однако
</P>
<P>* M. Мinsky (ed.). Semantic Information Processing, p. 1.</P>
<P>** Ibid., p. 26.<P>  *** Ibid.rP; 18.</P>
<P>
**** M.Minsky. Computation: Finite and Infinite Machines. Engluwood Cliffs, N 
J., Prentice-Hall, 1967, p. 2.
</P>
<P>***** M.Minsky (ed.). Semantic Information Processing, p. 13.</P>
<P class=Page>96</P>
<P>
предлагаемые Минским решения остаются, как правило, на уровне приемов ad hoc, 
и тем не менее с некоторой долей беспечности он пишет далее:
</P>
<P>
"Рассмотренные в данной книге программы все еще страдают этим недостатком, но 
их авторы уже не игнорируют этой проблемы. Их основная задача фактически 
состоит в том, чтобы решить ее"*.
</P>
<P>
Но как-то незаметно, чтобы хоть одна из представленных М, Минским работ 
что-нибудь решала. Ни одной общей характеристики способности человека к 
разумному поведению найти не удалось. Все, что предлагает Минский, - это 
частные решения отдельных задач, как у Боброва и Эванса, или предельно 
упрощенные модели, как у Квиллиана, которые работают именно потому, что 
проблема структурирования и хранения необходимого объема данных была исключена 
из рассмотрения. Минский, конечно, уже ответил на эти очевидные обвинения новой 
вариацией на тему "первого шага":
</P>
<P>
"Хотя область применения предлагаемого пакета программ see еще производит 
впечатление довольно узкой, это не доказывает отсутствия прогресса в движении к 
более общим результатам. Каждая из этих программ - шаг вперед к управлению 
знанием"**.
</P>
<P>
По-видимому, на втором этапе игра заключается в следующем: выяснить, в какой 
мере можно наращивать видимость сложного, оставаясь в то же время на безопасном 
расстоянии от подлинной проблемы сложности, а затем, убедившись, что обобщение 
невозможно, объявить, что сделан только первый шаг49.
</P>
<P>
Такой подход неизбежен до тех пор, пока исследователи в области ИИ будут 
стремиться к эффективным результатам, не решив практической задачи хранения в 
памяти большого объема данных, необходимого - хотя, быть может, и 
недостаточного - дли всесторонней гибкой переработки семантической информации. 
Оглядываясь на достигнутые результаты, М. Минский с удовлетворением отмечает: 
"Трудно сдержать изумление, видя, как много все-таки достигнуто при столь 
ограниченной семантике"***. И. Бар-Хиллел в беседе с представителями SIGART 
(Special Interest Group in Artificial Intelligence of the Association for 
Computing Machinery} подчеркнул, что такого рода заявления лишь вводят в 
заблуждение:
</P>
<P>
"Существует немало людей во всех областях знания и особенно в сфере ИИ, которые 
расценивают любой первый шаг в использовании ЭВМ там, где
</P>
<P>* Ibid.</P>
<P>** Ibid, (курсив мой,- Х.Д.)</P>
<P>*** Ibid., p. 26.</P>
<P class=Page>97</P>
<P>
они ранее не применялись, как такое достижение, которое делает оставшиеся шаги 
делом "простой техники". В сущности, такая точка зрения равносильна 
утверждению, что если какая-то работа может быть вообще передана вычислительной 
машине, то она будет выполняться ею хорошо. Дело обстоит как раз наоборот: шаг, 
ведущий от полной невозможности выполнить что-то к возможности выполнить это 
хоть как-нибудь, значительно короче следующего шага, приводящего к умению 
выполнить это хорошо. В исследованиях в области ИИ подобное заблуждение 
встречается постоянно"*.
</P>
<P>
Однако И.Бар-Хиллел, пожалуй, излишне простодушен, если полагает, что это 
непонимание является простым следствием недооценки трудностей, связанных с 
прогрессом в данной области. Для того чтобы иметь основание утверждать, что 
первый, пусть даже маленький шаг уже сделан, надо быть уверенным в том, что 
последующие шаги в конце концов достигнут желаемой цели. Как мы видели, книга 
М. Минского таких оснований не дает. Вполне возможно, что вышеупомянутые шаги 
окажутся семимильными шагами в противоположном направлении. Ограниченность 
результатов, описываемых Минским, в сочетании с тем фактом, что за последние 
пять лет ни одно из множества прокламированных обобщений не было реализовано, 
наводят на мысль, что человек в отличие от ЭВМ вовсе не имеет дела с массой 
изолированных фактов, поэтому ему нет необходимости накапливать и извлекать из 
памяти эти факты, пользуясь эвристическими правилами. Судя по его поведению, 
человек обходит те трудности, с которыми на каждом шагу сталкиваются 
исследователи в области моделирования процесса познания и создания 
искусственного интеллекта, он делает это, избегая дискретного метода 
переработки информации, который эти трудности вызывает. Таким образом, весьма 
сомнительно, чтобы тот сдвиг, который М. Минский называет шагом к управлению 
"знанием" (пусть незначительным шагом), вообще вел к искусственному интеллекту.
</P>
<a name="13">
<B><P>ЗАКЛЮЧЕНИЕ</P></B>
<P>
Как мы видели, первый этап - этап, провозглашенный "первым шагом", - не привел 
к успеху. Это относится как к GPS, так и вообще ко всем программам 
моделирования доказательства теорем, игры в шахматы и перевода с одного 
естественного языка на другой, созданным на этом этапе, М. Минский и сам 
признает неудачу; его диагноз точен, хотя он и пытается свести понесенные 
потери к минимуму:
</P>
<P>* Y.Bar-Hillel. Critique of June 1966 Meeting, SIGART Newsletter, p.1.
</P>
<P class=Page>98</P>
<P>
Несколько исследований, по существу, не оправдали возлагавшихся на них надежд- 
Я имею в виду весьма нашумевшие проекты по переводу с одного языка на другой и 
доказательству математических теорем. Я думаю, что в обоих случаях это были 
незрелые попытки комплексной формализации, не подкрепленные достаточно глубоким 
постижением смысла самих объектов формализации"*.
</P>
<P>
Второй этап - новый "первый шаг" - начался где-то в 1961 г., когда в 
Массачусетсом технологическом институте ученики Минского начали работать над 
диссертациями, темы которых были определены задачей преодоления этих 
трудностей. Его конец можно отнести к 1968 г., когда вышла в свет книга под 
редакцией М. Минского "Процессы переработка семантической информации" - своего 
рода отчет об этих попытках, завершенных уже к 1964 г. Учитывая, по общему 
признанию, узкий -ad hoc - характер соответствующих программ, которые Минский 
считает наиболее удачными, и отмечая отсутствие дальнейшего их развития за 
последние пять лет, мы можем сделать единственный вывод: второй этап тоже не 
привел к успеху.
</P>
<P>
Авторы большинства работ, посвященных описанию состояния дел в этой области, не 
подчеркивают этот факт. Р.Соломонов в своем обзоре, опубликованном в "Трудах 
Института инженеров по электротехнике и радиоэлектронике" в 1966 г. и 
посвященном обзору работ в области ИИ, вышедших после 1960 г., первые три 
страницы уделяет программе GPS и другим достижениям прошлого, уже завершенным к 
1960 г.; на следующих трех страницах обсуждается блестящее будущее работы 
С.Амареля, посвященной индукции: "Хотя Амарель не представил ни одну из своих 
теорий в виде программы, важность его идей и проведенного им анализа 
несомненна"**. О программах для переработки семантической информации, которым 
М. Минский придает такое значение, почти ничего не говорится. Все надежды 
возлагаются на индукцию и обучение. К сожалению, "во всех упомянутых 
обучающихся системах машина может самосовершенствоваться только в очень 
ограниченных пределах... Перед нами все еще стоит вопрос о том, какого типа 
эвристики требуются для нахождения эвристик; неизвестно также, в каких языках 
удобнее их описывать"***.
</P>
<P>
Поскольку не нашлось никого, кому удалось бы хоть что-нибудь сделать для 
нахождения таких эвристик, Р.Соломонов возлагает свои последние надежды на 
искусственную эволюцию;
</P>
<P>
"Перспективность  искусственной  эволюции объясняется  тем, что о механизмах 
естественной эволюции мы знаем очень много и о многом
</P>
<P>* М.Минский. Искусственный разум. - В кн.: Информация, с.214.
</P>
<P>
** R.Sоlоmоnоff. Some Recent "Work in Artificial Intelligence.-Pro 
ceedings  of the IEEE, vol.54, No. 12, 1966, December, p. 1689.
</P>
<P>*** Ibid., p. 1691.</P>
<P class=Page>99</P>
<P>
догадываемся. А ведь эти механизмы могут быть прямо или косвенно использованы 
для решения тех проблем, которые возникают в их искусственных аналогах. 
Моделирование эволюции предоставляет исследователям в области "искусственного 
интеллекта" несравнимо более богатые возможности, чем моделирование нейронных 
сетей, поскольку о нейронных сетях почти ничего не известно из того, что могло 
бы хоть сколько-нибудь помочь в решении сложных проблем"*.
</P>
<P>
Однако такого рода работа по искусственной эволюции только начинается. 
"Исследования в области моделирования эволюции до сих пор чрезвычайно 
ограничены как количественно, так и качественно"**.
</P>
<P>
Когда статья, предназначенная для подведения итогов работы, проделанной с 1960 
г., начинается с упоминания достижений предшествующих лет и кончается общими 
рассуждениями без единого примера, подтверждающего действительный прогресс, то 
между строк с отчетливостью проступают признаки застоя.
</P>
<P>
Подчас и в самих строках можно уловить оттенок разочарования. Так, например, 
Ф.Тонг в своей серьезной, без претензий статье об эвристическом алгоритме 
балансирования работы сборочного конвейера, опубликованной в 1968 г, и позднее 
вошедшей в коллективный труд "Вычислительные машины и мышление”, заканчивает 
обзор работ по "искусственному интеллекту" следующими славами;
</P>
<P>
"Несмотря на создание множества интересных программ (и нескольких любопытных 
устройств), прогресс в области "искусственного интеллекта" нельзя назвать ни 
волнующим, ни блестящим... По крайней мере в некоторой степени это связано с 
тем, что во многих публикациях, и в прошлом, и в настоящем, отсутствует четкое 
различение того, что достигнута, и того, что еще предстоит сделать. В этой 
области, как и во многих других, существует огромная разница между 
утверждением, что то или иное усовершенствование "по всей вероятности может 
быть" реализовано, и его действительной реализацией.
</P>
<P>
Очень мало ощутимых, значительных переломных достижений"***.
</P>
<P>
Затем Тонг перечисляет те достижения, которые он считает "переломными". Сюда 
входят: программа Ньюэлла, Шоу и Саймона "Логик-теоретик", шашечная программа 
Сэмюэля и распознающая программа Л.Юра и Ч.Фосслера. Но все три работы 
закончены задолго до 1961 г. и все три - тупиковые, если об этом позволительно 
судить по дальнейшим работам.
</P>
<P>
Чтобы отклонить возможные упреки в пристрастности моей оценки этой обзорной 
работы Тонга, сошлюсь для сравнения на следующий принадлежащий П. Гринвуду 
реферат, помещенный в реферативном журнале "Computing Reviews": "Из этого   
сжатого    описания    сегодняшнего    состояния    дел    по
</P>
<P>* Ibid. p. 1693.</P>
<P>** Ibid.</P>
<P>*** F.M.Tonge. A View   of   Artificial   Intelligence.- In:   Proceedings, 
A.CM.National Meeting, 1966, p. 37950.
</P>
<P class=Page>100</P>
<P>
проблеме "искусственного интеллекта можно сделать вывод, что за период, 
истекший с 1960 г., прогресс в этой области был весьма незначителен, а 
перспективы на ближайшее будущее оставляют желать лучшего"*.
</P>
<P>
Остается непонятным, почему эти трудности не смущают исследователей, работающих 
в области моделирования процесса познания, которые полагают, что переработка 
информации, производящаяся вычислительной машиной, проливает свет на скрытые от 
нас информационные процессы у человека, и почему те, кто занимается 
"искусственным интеллектом", считают, что должен существовать дискретный метод 
решения тех задач, которые разрешимы для человека. Насколько мне известно, в 
этой области исследований не нашлось никого, кто задумался бы над этими 
вопросами. Фактически во всем конгломерате естественных наук "искусственный 
интеллект" представляет собой наименее самокритичную область. Должна же 
существовать какая-то причина, объясняющая тот факт, что все эти разумные люди 
почти единогласно сводит к минимуму или вообще отказываются видеть возникающие 
на их пути трудности и продолжают догматически верить в успех. Очевидно, 
какая-то сила, заключающаяся в их исходных допущениях (а отнюдь не в успехах их 
работ), заставляет их игнорировать необходимость оправдания этой уверенности. 
Теперь нам необходимо разобраться, почему, несмотря на всевозрастающие 
трудности, исследователи в области "искусственного интеллекта" сохраняют столь 
непоколебимую твердость.
</P>
<P>* Computing Reviews, vol. 8, No, 1, 1967, January-February, p. 31</P>
<P class=Page>101</P>
<a name="20">
<HR>
<B><P>Часть II</P>
<P>ДОПУЩЕНИЯ, ЛЕЖАЩИЕ В ОСНОВЕ "СТОЙКОГО ОПТИМИЗМА</P>
<P>ВВЕДЕНИЕ</P></B>
<P>
Несмотря на серьезные трудности, исследователи, работающие в области 
моделирования процесса познания и создания "искусственного интеллекта", не пали 
духом. Более того, они настроены на редкость оптимистично. Их оптимизм основан 
на убеждении, что у человека переработка информации, вне всякого сомнения, 
носит дискретный характер, подобно тому как это происходит в цифровой машине, 
Коль скоро природа, основываясь на этом принципе, уже реализовала разумное 
поведение, то, составив соответствующую программу, мы имеем возможность 
наделить такой же способностью и вычислительные машины. При этом мы можем идти 
по пути имитации природы, либо программирования ее внешних проявлений.
</P>
<P>
Предположение, согласно которому как у человека, так и у машины переработка 
информации в конечном счете основана на одних и тех же элементарных действиях, 
высказывается порой с наивной откровенностью. А.Ньюэлл и Г.Саймон начинают одну 
из своих статей следующим замечанием:
</P>
<P>
"Ясно, что при таком подходе не делается каких-либо предположений о сходстве 
конструкции машины и мозга, за исключением того, что обе эти системы 
представляют собой универсальные устройства символьной переработки информации, 
и того, что должным образом запрограммированная вычислительная машина может 
выполнять элементарные информационные процессы в функциональном отношении точно 
так же, как они происходят в мозгу"*.
</P>
<P>
Это предположение, однако, не столь невинно и очевидно, как представляется на 
первый взгляд. Что такое "универсальное устройство символьной переработки 
информации"? Каковы те "элементарные информационные процессы", которые, как 
утверждается, одинаковы для человека и машины? Все работы по "искусственному 
интеллекту" осуществляются на цифровых машинах, поскольку это единственное 
универсальное устройство переработки информации, которое мы в настоящее время 
умеем конструировать и вообще можем себе представить. Вся информа-
</P>
<P>
A.Newell, H.A.Simоn. Computer Simulation of Human Thinking.- The RAND 
Corporation, P-2276, 1961, April 20, p. 9
</P>
<P class=Page>105</P>
<P>
ция, с которой работают эти ЦВМ, должна быть выражена в терминах дискретных 
элементов. Для современных цифровых машин информация представляется в двоичной 
форме, то есть в виде последовательностей сигналов "да" и "нет" либо "включено" 
и "выключено". Машина должна обрабатывать строчки определенных элементов 
конечной длины как последовательности объектов, отношения между которыми 
задаются строгими правилами. Таким образом, предположение, согласно которому 
человек действует подобно устройству для символьной обработки информации, 
связано со следующими допущениями.
</P>
<P>
1. Биологическое допущение: на некотором уровне - обычно
полагают, что на уровне нейронов, -операции по переработке информации носят 
дискретный характер и происходят на основе некоторого биологического 
эквивалента переключательных схем,
</P>
<P>
2. Психологическое допущение: мышление можно рассматривать как переработку 
информации, заданной в бинарном (двоичном)  коде51, причем переработка 
происходит в соответствии с некоторыми формальными правилами. Таким образом, в 
психологии вычислительная машина служит в качестве модели рассудка, каким его 
представляли эмпирики, такие, например, как Д.Юм  (в этом случае информационным 
"битам" соответствуют атомарные впечатления), или идеалисты вроде И.Канта {в 
этом случае программа реализует правила мыслительного процесса) . Они 
подготовили почву для модельного представления мышления в виде процесса 
переработки информации - безличного процесса, в котором "процессор" не играет 
существенной роли52.
</P>
<P>
3. Эпистемологическое допущение:  все знания могут быть
формализованы, то есть все, что может быть понято, может быть выражено в 
терминах логических отношений, точнее, в терминах булевых функций - логического 
исчисления, задающего правила обращения с информацией, заданной в двоичном 
коде53.</P>
<P>4. Наконец, поскольку вся информация, которая вводится в
машину,  должна  быть представлена в двоичной  форме - в битах,- машинная 
модель мышления предполагает, что все сведения о мире, все, что составляет 
основу разумного поведения, должно в принципе допускать анализ в терминах 
множества элементов, безразличных к ситуациям. Таково онтологическое допущение: 
все, происходящее в мире, можно представить в виде множества фактов, каждый из 
которых логически не зависит от остальных. В следующих главах мы перейдем к 
анализу правдоподобия каждого из этих допущений. Мы убедимся, что, как правило, 
то, что исследователям, работающим в области моделирования процесса познания и 
создания "искусственного интеллекта", представляется аксиомой, гарантирующей 
получение результатов, в действительности является лишь одной из возможных 
гипотез, подлежащих проверке в ходе дальнейшей работы. Более того, ни
</P>
<P class=Page>106</P>
<P>
одно из этих четырех допущений не может быть оправдано ни эмпирически, ни a 
priori. Наконец, последние три допущения - носящие скорее философский, чем 
эмпирический характер,- можно подвергнуть критике с философских позиций. Каждое 
из них при последовательном применении к осмыслению разумного поведения ведет к 
затруднениям концептуального характера.
</P>
<P>
После анализа каждого из этих допущений нам будет легче понять устойчивый 
оптимизм специалистов в области "искусственного интеллекта", а также оценить 
действительную значимость результатов, полученных ими к настоящему времени.
</P>
<BR>
</TD>
</TR>

</TABLE>

<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" WIDTH="80%">

<TR>
<TD>
<a name="23">
<B><P>Глава 3. БИОЛОГИЧЕСКОЕ ДОПУЩЕНИЕ</P></B>
<P>
В период между изобретением телефонного реле и созданием
вычислительной машины - этой кульминации принципа, заложенного в основу работы 
реле,- мозг всегда представлялся в терминах новейших технических достижений: 
его функционирование
мыслилось по аналогии с работой большой телефонной станции, а
значительно позднее - с электронной вычислительной машиной.
</P>
<P>
Эта модель мозга связана и с исследованиями в области нейрофизиологии, в 
результате которых было обнаружено, что нейроны дают всплески электрической 
активности по принципу "все или ничего". Такой всплеск, или импульс, стали 
рассматривать как
единицу информации, циркулирующей в мозгу, подобно машинному "биту". Эта 
модель, и по сей день некритически принимаемая всеми, кто непосредственно не 
связан с нейрофизиологией, и является основой наивного представления о тоги, 
что человек - это ходячий пример успешно работающей программы для цифровой 
вычислительной машины.		
</P>
<P>
Начнем с того, что, даже если бы мозг на некотором уровне действительно работал 
подобно цифровой машине, это совсем не обязательно оправдало бы надежды 
специалистов в области моделирования познавательных процессов и "искусственного 
интеллекта". В самом деле, можно представить себе, что мозг смонтирован как 
большое скопление случайно соединенных нейронов. Именно по такому принципу был 
построен перцептрон, предложенный группой "ранних кибернетиков", как их 
пренебрежительно называет М.Минский*. Такая нейронная сеть может быть 
промоделирована с помощью программы для вычислительной машины, однако подобная 
программа не будет эвристической
</P>
<P>
* В свете предстоящего анализа следует заметить, что, даже если удастся 
показать, что перцептроны из некоторого узкого класса подобных систем 
неспособны к распознаванию образов или обучению (см. с. 79) , это не исключает 
теоретической возможности того, что достаточно сложная ней­ронная сеть проявит 
эту способность. Такую возможность не следует упускать из виду при оценке тех 
аргументов в пользу биологического и психологического допущений, согласно 
которым мозг или мышление должны функционировать по типу эвристически 
запрограммированной цифровой вычислительной машины.
</P>
<P class=Page>108</P>
<P>
ни в каком смысле этого слова. Таким образом, тот факт, что мозг может 
оказаться цифровой машиной, отнюдь не дает достаточно оснований для 
оптимистических настроений относительно возможности создания искусственного 
интеллекта, как его определяют Саймон и Минский.
</P>
<P>
Более того, вопрос о том, в какой мере элементарные информационные процессы 
мозга могут быть поняты в терминах цифровой модели, требует экспериментальной 
проверки. Мозг, быть может, перерабатывает информацию совершенно иным, 
полностью отличным от машинного способом. Информация, например, может 
перерабатываться глобально, подобно тому как это происходит в состоящих из 
электрических сопротивлений аналоговых схемах при решении задач на определение 
кратчайшего пути в некоторой сети. Как показали многочисленные 
экспериментальные данные, модель мозга, построенная на "нейронных 
переключателях", практически не находит подтверждения. Уже в 1956 г. Дж. Нейман 
- один из создателей современной вычислительной техники - высказал следующие 
сомнения:
</P>
<P>
"Если теперь говорить конкретно о нервной системе человека, то это- механизм 
огромной сложности, по крайней мере в 1СР раз большей, чем любой известный нам 
искусственный механизм, и его действия соответственно этому разнообразны и 
сложны. В число функций этого механизма входит интерпретация внешних 
чувственных восприятий, а также сообщений о физических или химических условиях, 
управление двигательной активностью и внутренними химическими уровнями, функция 
памяти с ее очень сложными действиями преобразования и отыскания информации и, 
разумеется, непрерывная передача кодированных приказов и более или менее 
количественно выраженных сообщений. Все эти процессы могут трактоваться при 
помощи цифровых методов (то есть с использованием чисел, выраженных в двоичной 
системе или при помощи некоторых дополнительных приемов кодирования, в 
десятичной или какой-либо другой системе), в терминах обработки цифровой 
(обычно числовой) информации алгебраическими (то есть в основном 
арифметическими) методами. Это наиболее вероятный путь, по которому в настоящее 
время пошел бы человек, пытаясь решить такую проблему ...доступные нам 
сведения, хотя они скудны и не точны, указывают, скорее на то, что нервная 
система человека использует иные принципы и процессы. Так, цепочки импульсов, 
по-видимому, передают информацию, используя аналоговый принцип (однако, в 
пределах импульсных кодов, то есть здесь мы имеем дело со смешанной системой, 
которая частично цифровая, частично аналоговая), как, например, временную 
плотность последовательности импульсов в одной линии, корреляции во времени 
серий импульсов в различных волокнах одного пучка и т. д."*.
</P>
<P>
Что он имеет в виду под "смешанным характером живых организмов", фон Нейман 
уточняет следующим образом:
</P>
<P>
* Дж. Нейман. Вероятностная логика и синтез надежных организмов из ненадежных 
компонент. - В сб.: Автоматы, под ред. К.Э.Шеннона и Дж. Маккарти. М., 1956, с, 
129 54
</P>
<P class=Page>109</P>
<P>
"Нейрон подает импульс. Нервный импульс в основном подчиняется принципу 
"включено - выключено", "все или ничего", и его можно срав­нить с двоичной 
цифрой. Таким образом, наличие цифрового элемента очевидно, но также очевидно, 
что это еще не все. Многое из того, что происходит в организме, обусловлено не 
явлениями этого рода, а зависит от общего химического состава крови и других 
гуморальных сред. Хорошо известно, что в организме имеется множество сложных 
функциональных цепей, в которых переход от первоначального раздражения к 
конечному эффекту осуществляется через целый ряд этапов; некоторые из этих 
этапов  являются  нейронными,  то есть цифровыми, другие - гуморальными, то 
есть аналоговыми"*.
</P>
<P>
Но даже и это описание отдает слишком большую дань цифровой модели. Из того 
факта, что нервные импульсы построены по принципу "все или ничего", вовсе не 
следует, что имеет место цифровой процесс в любой его форме. Различие между 
цифровым и аналоговым вычислением - это логическое различие, которое не зависит 
ни от конструкции системы, ни от вида используемых в ней электрических 
импульсов. Существенное различие между цифровым и аналоговым способами 
переработки информации состоит в том, что при цифровом способе отдельный 
элемент представляет символ некоторого описательного языка, то есть несет 
конкретный квант информации, тогда как в устройствах, работающих по аналоговому 
принципу, подлежащая обработке информация представляется непрерывными 
физическими величинами. Мозг, оперирующий потоками импульсов, можно считать 
цифровым вычислительным устройством только в том случае, если каждый импульс 
окажется связанным с определенным шагом в процессе переработки информации; если 
же, напротив, обнаружится, что минимальной "единицей" в модели информационного 
процесса должна быть частота импульсации - как, по-видимому, считает Нейман,- 
то мозг работает как аналоговое устройство**.
</P>
<P>
После такого разъяснения понятий мы можем считать, что фон Нейман предложил 
чисто аналоговую модель работы мозга; и последующие исследования, видимо, это 
подтверждают. Даже для тех, кто не знаком со специальными вопросами, которым 
посвящена цитируемая ниже работа, понятен смысл следующих слов:
</P>
<P>
"У высших беспозвоночных мы впервые сталкиваемся с такими явлениями, как 
нарастающий синаптический потенциал, при котором перед возникновением 
постсинаптического импульса происходит алгебраическое сложение действия 
нескольких входных пресинаптических воздействий, осуществляемое сложным 
механизмом. Эти входные воздействия имеют различную значимость в зависимости от 
характера проводящего пути и состояния синапса. Это нелинейное и локальное 
явление, предшествующее
</P>
<P>
* Дж. фон Нейман. Общая и логическая теория автоматов55-- В кн.: А.Тьюринг. 
Может ли машина мыслить? М., 1960, с. 70.
</P>
<P>
** Это различение мне помогли сформулировать У. Эльзассер и П. Грегори, за что 
я им весьма признателен.
</P>
<P class=Page>110</P>
<P>возникновению всякого постсинэптического импульса, может быть настолько 
существенным, что мы не можем более считать типичный синапс в интегрирующих 
системах чисто цифровым устройством, как обычно предполагалось несколько лет 
назад. Это, скорее, сложное аналоговое устройство"*
</P>
<P>
Сравнительно недавно Дж. Летвин, сотрудник Массачусетского технологического 
института, высказал предположение, что толщина аксона может играть решающую 
роль в переработке информации, так как она определяет параметры аксона как 
фильтра**.
</P>
<P>
Отдельный нейрон возбуждается с определенной частотой. Различные ветви его 
аксона действуют как низкочастотные фильтры, полоса пропускания которых 
определяется диаметром ветви. Поэтому выходной сигнал клетки будет вызывать 
сигналы раз-ных частот на разных окончаниях аксона. Вообще характеристики 
аксона как фильтра изменяются с его диаметром, который в свою очередь, быть 
может, зависит от времени, прошедшего с момента предыдущего его "срабатывания", 
и даже, возможно, от активации непосредственно примыкающих аксонов. Если 
подобные временные факторы и пространственные взаимодействия играют решающую 
роль, то нет никаких оснований надеяться, что переработка информации на 
нейрофизиологическом уровне может быть описана в терминах цифрового формализма 
или какого бы тони было формализма вообще56.
</P>
<P>
В 1966 г. У. Розенблит, также сотрудник Массачусетского технологического 
института и один из пионеров использования ЭВМ в нейрофизиологии, подвел итоги 
сложившейся ситуации следующим образом:
</P>
<P>
"Более того, мы не придерживаемся ранее широко распространенного мнения, что 
закон передачи нервных импульсов по так называемому принципу "все или ничего" 
дает нам право считать реле хорошей моделью нейрона. Кроме того, на нас 
производит все большее впечатление то взаимодействие, которое имеет место между 
нейронами: в некоторых случаях последовательность нервных импульсов может 
достаточно четко отражать работу буквально тысяч нейронов. Но если мы имеем 
дело с системой, многочисленные элементы которой вступают между собой в столь 
сильное взаимодействие, то описание в терминах поведения индивидуальных 
нейронов вряд ли обеспечит ее наилучшее понимание... Попытка установления 
детальной аналогии между организацией мозга и структурой вычислительной системы 
была бы тщетной и неубедительной"***.
</P>
<P>
Итак, точка зрения, согласно которой мозг как универсальная система переработки 
символьной информации работает подобно
</P>
<P>
* Th.H.Bullосk. Evolution of Neurophysiological Mechanisms.- In: Behavior 
and Evolution, A.Roe and G.Simpson (eds.), New Haven, Conn., Yale University 
Press, 1958,   p. 172.
</P>
<P>
** J. Lettvin. Lecture at the University of California. Berkeley, November 
1969.
</P>
<P>
*** W. A. Rоsenblith. On Cybernetics and the Human Brain.-The 
American Scholar, 1966, Spring, p, 247,
</P>
<P class=Page>111</P>
цифровой машине, является эмпирической гипотезой, время 
которой уже прошло. Современные экспериментальные данные о 
работе мозга не дают никаких аргументов в пользу возможности 
создания "искусственного интеллекта". В действительности мы 
отчетливо видим различие между организацией мозга, основанной 
на "сильном взаимодействии" его элементов, и структурой 
машины, лишенной такого взаимодействия. Если признать 
биологические данные существенными, то это различие свидетельствует против 
возможности создания интеллекта на базе цифровых ЭВМ. </P>
<a name="24">
<B><P>Глава 4. ПСИХОЛОГИЧЕСКОЕ ДОПУЩЕНИЕ </P></B>
<P>
Вопрос о том, действует ли мозг подобно цифровой машине, является чисто 
экспериментальным, и разрешить его должна нейрофизиология. "Компьютерная" 
модель просто не согласуется с фактами. Однако нельзя дать столь однозначный 
ответ на связанный с предыдущим, но совершенно иного плана вопрос; работает ли 
разум на тех же принципах, что и цифровая вычислительная машина, то есть 
оправдано ли применение машинно-цифровой модели в психологии? В данном случае 
значительно труднее определить суть вопроса. Мозг - это, безусловно, физический 
объект, в котором происходит преобразование энергии физического мира на основе 
физических процессов. Но, коль скоро психология отличается от биологии, 
психолог обязан выделить несколько иной уровень функционирования, чем уровень 
физико-химических реакций мозга.
</P>
<P>
Теория, которую мы будем оспаривать, утверждает, что такой уровень существует и 
это - уровень информационных процессов. Формируя на этом уровне разумное 
поведение, наше мышление использует вычислительные процессы, такие, как 
сравнение, классификация, перебор и т. д. Согласно этой теории, такой 
ментальный уровень - уровень, отличный от уровни физических процессов,-должен 
быть введен в рассмотрение как некоторый возможный языково-мыслительный 
уровень. Поэтому вопросы, которые здесь будут обсуждаться, носят скорее 
философско-теоретический, чем опытно-экспериментальный характер. Мы убедимся, 
что допущение существования уровня "информационных процессов" отнюдь не столь 
самоочевидно, как это полагают специалисты по моделированию процессов познания, 
что имеются веские основания сомневаться в самой возможности какой бы то ни 
было "переработки информации" вообще и что, следовательно, тезис о том, что 
мышление построено на принципах цифровой вычислительной машины, также 
представляется сомнительным,
</P>
<P>
В 1957 г. Саймон предсказывал, что через десять лет психологические теории 
примут форму программ для вычислительных машин, и он сам принялся за воплощение 
своего предсказания, составив серию программ, которые, как он полагал, 
моделируют
</P>
<P class=Page>113</P>
<P>процесс человеческого познания. В них должны были быть отражены сознательные 
и подсознательные шаги, осуществление которых приводит личность к специфически 
разумной деятельности. Как мы уже видели, несмотря на общее несоответствие 
подобных программ их замыслу (признаваемое даже таким энтузиастом, как 
Минский), все специалисты в области "искусственного интеллекта" (включая 
Минского) разделяют мнение о том, что разумное поведение людей основано на 
определенных эвристических правилах, некоторое подобие которых и следует ввести 
в ЭВМ для обеспечения такого же рода машинного поведения.
</P>
<P>
Более того, несмотря на ограниченность результатов, предсказание Саймона в 
некотором смысле сбылось. В психологии 
произошел общий сдвиг от бихевиоризма к ментализму. Многие 
влиятельные психологи и философы, занимающиеся проблемами 
психологии, перешли на сторону Саймона и стали формулировать 
свои проблемы в терминах, основанных на аналогии с вычислительными машинами. 
Так, У.Ниссер полагает, что "задача психолога, пытающегося понять механизм 
человеческого познания, подобна попытке выяснить, как запрограммирована 
вычислительная машина"*. А Дж. Миллер из Гарвардского университета говорит о 
"новейших достижениях в области понимания человека, рассматриваемого как 
система, перерабатывающая информацию"**.	
</P>
<P>
Обычно в пользу этой новой догмы о том, что человек - это система переработки 
информации, действующая подобно эвристически запрограммированному "компьютеру", 
не приводится никаких аргументов. Создается впечатление, что это утверждение - 
безусловная аксиома, так как в противном случае оно требовало бы тщательного и 
критического анализа. Поскольку мозг физически реален и, образно выражаясь, 
"перерабатывает информацию", постольку существует известный соблазн 
предположить, что должен существовать некоторый уровень "информационных 
процессов" - некая динамическая операциональная структура, в терминах которой 
может быть описана информационная активность мозга. Однако, как мы видели в 
главе 3, именно потому, что мозг материален и производит переработку 
информации, биологи не видят никаких оснований считать, что он работает подобно 
цифровой вычислительной машине. Это верно и для психологического уровня. Хотя 
психологи и описывают функцию мозга, называемую разумом, как "процесс 
переработки
</P>
<P>* U.Neisser, Cognitive Psychology. New York, Appleton-Century-Crofts,
1967, p. 6. </P>
<P>** См.: Дж. Миллер,   Е. Галантер   и   К. Прибрам. Планы и
структура поведения, с. 74.	</P>
<P class=Page>114</P>
<P>информации", это совсем не значит, что мозг действительно перерабатывает 
информацию в принятом в современной литературе смысле этого выражения или что 
мозг работает как цифрован машина, то есть обладает некоторой программой.
</P>
<P>
Выражение "переработка информации", или "информационный процесс", 
неоднозначно. Если оно означает просто то, что наш разум на основе одних 
осмысленных образований строит другие осмысленные образования, то это 
утверждение, конечно, неопровержимо. Но кибернетическая теория информации, 
восходящая к работе К. Шеннона 1948 г., не имеет ничего общего со "смыслом" 
(или "значением") в обычном словоупотреблении. Математическая теория пропускной 
способности канала передачи сообщений совсем не связана с семантикой. Один бит 
(двоичная единица) информации сообщает своему получателю только о том, какая из 
двух равновероятных альтернатив реализовалась.
</P>
<P>
В своей классической работе "Математическая теория связи" К. Шеннон совершенно 
ясно указывает на то, что его теория, исследующая задачи, возникающие в 
телефонной связи, полностью игнорирует как несущественное значение передаваемых 
сообщений.
</P>
<P>
"Основная задача связи состоит в точном или приближенном воспроизведении в 
некотором месте сообщения, выбранного для передачи в другом месте. Часто 
сообщения имеют значение, то есть относятся к некоторой системе, имеющей 
физическую или умозрительную сущность, или находятся в соответствии с некоторой 
системой. Эти семантические аспекты связи не имеют отношения к технической 
стороне дела"*.
</P>
<P>
У.Уивер, объясняя значение работы Шеннона, высказывается еще более выразительно:
</P>
<P>
«В этой теории слово информация используется в специальном смысле, который не 
следует смешивать с обычным словоупотреблением. В частности, информацию не 
следует путать со "значением"» .
</P>
<P>
На самом деле два сообщения, в одном из которых заложен глубокий смысл, а 
другое являет собой чистую бессмыслицу, могут быть абсолютно эквивалентны с 
точки зрения несомой ими информации, коль скоро она понимается в современном 
смысле слова. Именно это, несомненно, имеет в виду Шеннон когда говорит, что 
"эти семантические аспекты связи не имеют отношения к технической стороне 
дела"**.
</P>
<P>
Когда, вопреки предупреждению К. Шеннона58 идеи и аппарат теории информации 
неправомерно переносят в сферу "теории значения", то под влиянием опыта работы 
с ЭВМ исходят из того,
</P>
<P>* К. Шеннон. Математическая теория связи57.- в кн.: К. Шеннон. Работы 
по теории информации и кибернетике. М., 1963, с. 243.</P>
<P>** W. Weaver. Recent Contributions to the Mathematical Theory of 
Communication,-In: C.Shannоn, W.Weaver (eds.) The Mathematical Theory
of Communication, Urbana, University of Illinois Press, 1962, p. 99.	
</P>
<P class=Page>115</P>
<P>что эмпирические данные могут быть разложены на изолированные, атомарные 
альтернативы. Но для "теории значения" такое допущение отнюдь не очевидно. 
Гештальтпсихологи, например (как мы уже видели в части I и детально рассмотрим 
в части III), заявляют, что мышление и восприятие включают целостные процессы, 
которые не могут быть поняты в терминах ряда последовательно или даже 
параллельно осуществляемых дискретных операций*. А поскольку мозг по крайней 
мере отчасти работает, видимо, как аналоговое устройство, то весьма вероятно, 
что и наш разум порождает мысли и восприятия на базе "полей", "сил", 
"конфигураций" и т. п.; по-видимому, это как раз то, что дано нам на 
феноменологическом уровне**.
</P>
<P>
Роль программиста именно в том и состоит, чтобы перевести осмысленные 
утверждения (содержащие информацию в ее обычном понимании) в последовательности 
дискретных и лишенных смысла двоичных цифр (информацию в техническом смысле 
слова), с которыми может иметь дело машина. Цель работ по "искусственному 
интеллекту" состоит в том, чтобы заставить ЭВМ выполнять этот перевод 
самостоятельно. Однако остается неясным, можно ли при этом обойтись без 
переводчика-человека.
</P>
<P>
Многие работы по моделированию процесса познания создают иллюзию успеха именно 
благодаря смешению обычного смысла слова "информация" с тем специальным 
значением, которое это слово приобрело за последнее время. Но для того, чтобы 
не затемнять философскую сторону дела, не следует предрешать основной вопрос: 
действительно ли человеческий интеллект предполагает регулярность операций над 
дискретными элементами? Вот почему, когда речь идет о человеке, требуется 
особая осторожность при употреблении слов "переработка информации" (в 
кавычках)59.
</P>
<P>
Более того, если бы даже наш разум перерабатывал информацию в смысле Шеннона, 
действуя тем самым как цифровая машина, это еще не дало бы оснований полагать, 
что он непременно придерживается определенной программы. Если бы мозг был сетью 
случайно соединенных нейронов, то мы не обнаружили бы никакой динамической 
структуры, никаких последовательностей, регулируемых правилами шагов, 
совершающихся на уровне информационных процессов 60.
</P>
<P>
* В этом контексте утверждение Ньюэлла, Шоу и Саймона о том, что им удалось 
объединить в одно целое результаты, полученные бихевиористами и гештальтистами, 
усвоив, с одной стороны, поведенческий подход, а с другой - согласившись с тем, 
что "человек представляет собой чрезвычайно сложно организованную систему" (А. 
Ньюэлл и Г, Саймон. GPS - программа, моделирующая процесс человеческого 
мышления- - В кн.: Вычислительные машины и мышление, с. 284), демонстрирует 
либо желание затемнить суть дела, либо полное непонимание основных достижений 
каждой из этих школ.
</P>
<P>
** См. часть III.
</P>
<P class=Page>116</P>
<P>Обе эти подмены понятий - смешение обычного и технического смыслов слова 
"информация" и неявный переход от вычислительной машины вообще к эвристически 
запрограммированной цифровой машине - способствуют ложному переходу от того 
факта, что мозг в определенном смысле перерабатывает сигналы, поступающие на 
его вход, к заключению о том, что мозг или разум выполняют некоторую 
последовательность действий дискретного характера. Это заблуждение в своей 
худшей форме представлено в недавно вышедшей работе Дж.Фодора. Поучительно 
проследить ход его рассуждений.
</P>
<P>
Фодор начинает с общеизвестных фактов, касающихся центральной нервной системы:
</P>
<P>
"Если точка зрения,согласно которой причиной восприятия глубины является 
текстурный градиент, истинна, а также если центральная нервная система 
действительно соответствует тому представлению о ней, которое сложилось у 
наиболее проницательных исследователей, то некоторые из тех вещей, которые 
выполняет нервная система, некоторые физические процессы, происходящие в ней, 
когда мы устанавливаем глубину, могут описываться такими понятиями, как 
"вычисление текстурных градиентов", "обработка информации о текстурных 
градиентах", "вычисление производных текстурных градиентов" и т.д."*.
</P>
<P>
Так Дж.Фодор приходит к заключению, что "всякая операция, выполняемая нервной 
системой, идентична некоторой последовательности элементарных операций"**.
</P>
<P>
Оставляя в стороне вызывающий недоумение вопрос об использовании в этом 
контексте выражения "обработка информации", мы можем возразить, что такая 
операция, как вычисление первой производной текстурного градиента, вполне может 
быть осуществлена на того или иного рода аналоговом устройстве. Поэтому у нас 
нет никаких оснований заключить, что "всякая операция, выполняемая нервной 
системой, идентична некоторой последовательности элементарных операций". 
Аналогично нет ни малейшего оправдания заявлению такого рода: "Для каждого типа 
поведения из "репертуара" данного организма предполагаемый ответ на вопрос: 
"Как осуществляется поведение этого типа?"- принимает вид набора специфических 
инструкций, позволяющих реализовать это поведение с помощью некоторого набора 
машинных операций"***.
</P>
<P>
Правдоподобность этого рассуждения объясняется тем фактом, что если бы психолог 
взял первую производную текстурного градиента, то его вычисление было бы 
произведено по определенным формальным правилам  (дифференциального исчисления),
</P>
<P>* J.A.Fodor. The Appeal to Tacit Knowledge in Psychological Explanation, - The 
Journal of Philosophy, vol. LXV, No 20,1968, October 24 p 632 
<P>** Ibid, p. 629. 
<P>*** Ibid., p. 637.
</P>
<P class=Page>117</P>
<P>которые могут быть реализованы на цифровой машине в виде ряда дискретных 
операций. Но утверждать, что мозг при вычислении текстурного градиента 
непременно осуществляет ряд операций, так же абсурдно, как утверждать, что, 
обращаясь по своим орбитам вокруг Солнца, планеты решают дифференциальные 
уравнения или что логарифмическая линейка (аналоговая машина), вычисляя 
квадратный корень, осуществляет ту же последовательность шагов, что и цифровая 
машина, которая ищет соответствующее значение, записанное в двоичной системе 
счисления.
</P>
<P>
Возможно, что для нахождения текстурного градиента или для моделирования других 
перцептивных феноменов может быть использован процесс перехода ионного раствора 
в равновесное состояние. Но верно ли, что в растворе, приближающемся к 
равновесию, осуществляется тот же ряд дискретных операций, что и в цифровой 
машине, решающей дифференциальные уравнения, которые описывают этот процесс? В 
данном случае в растворе в считанные мгновения происходит процесс решения 
задачи, которую цифровой машине пришлось бы решать веками, если бы вообще она 
получила решение. Чем это объясняется? Может быть, тем, что раствор - это в 
высшей степени быстродействующая вычислительная машина? Или же тем, что он 
упрощает задачу с помощью разумных эвристик, как это делает шахматист при 
выборе нужного хода? Очевидно, ни тем, ни другим. Мы можем описать процесс 
перехода в состояние равновесия в форме дифференциальных уравнений, а затем для 
реализации его с помощью машины разбить решение этих уравнений на дискретные 
операции. Но это вовсе не значит, что сам процесс перехода в состояние 
равновесия происходит дискретно. Точно так же из того факта, что все 
непрерывные психохимические процессы, участвующие в человеческих 
"информационных процессах", могут быть в принципе формализованы и рассчитаны в 
дискретной форме, вовсе не следует, что какие-либо дискретные процессы имеют 
место в действительности.
</P>
<P>
Более того, если бы даже кто-то смог написать такую программу, которая 
моделировала бы психохимические процессы мозга, она оказалась бы совершенно 
бесполезной для психологии.
</P>
<P>
Если понимать моделирование в самом слабом смысле слова, то любая программа 
будет моделировать любое данное устройство, если она осуществляет то же самое 
преобразование "вход - выход" (в заданной области), что и это устройство. 
Возможна или нет такая модель для мозга - во всяком случае, ясно одно: она не 
обладает необходимым с точки зрения психологической теории свойством - быть 
средством оценки действительной "работы" разума. Для психологического 
объяснения требуется, чтобы способ представления, соответствие были в некотором
</P>
<P class=Page>118</P>
<P>смысле более сильными, чем простое моделирование. Фодор отмечает:</P>
<P>
"Мы можем сказать, что машина сильно эквивалентна организму в определенном 
отношении, если она слабо эквивалентна в том же отношении и если процессы, 
определяющие поведение машины, относятся к тому же типу, что и процессы, 
определяющие поведение организма"*.
</P>
<P>
Это значит, что эквивалентность в плане психологии предполагает существование в 
машине процессов психологического типа**. К психологическим операциям относятся 
такие процессы, которые при переработке информации человеком, по крайней мере 
иногда, осуществляются сознательно - например, поиск, сортировка, хранение 
данных. Эти процессы отнюдь не являются психохимическими реакциями организма. 
Представим себе, что шахматист в следующих словах говорит о том, каким образом 
он сосредоточивает свое внимание на ладье: "Теперь мой мозг достиг 
определенного химического равновесия, описываемого некоторой
</P>
<P>
* J.Fodor. Psychological Explanation. New York, Random House, 1968, p. 138.
</P>
<P>
** Утверждение о моделируемости допускает еще одно прочтение,- прочтение, 
которое адекватно "менталистской" установке, однако, к сожалению, не отличается 
непосредственной убедительностью, свойственной приведенному выше. Его суть 
сводится к тому, что для каждого аналогового процессора также можно найти 
нечто, ему соответствующее,- его представление. Однако, чтобы нащупать слабое 
место этого истолкования, нам потребуется привести несколько примеров на 
различие между моделированием и тем, что мы имеем s виду под представлением- 
Деление с помощью логарифмической линейки моделируется посредством любого 
алгоритма, позволяющего найти соответствующее частное; но сказать, что мы нашли 
представление этой операции, можно только в том случае, если частное получается 
способом, близким к принципу, заложенному в логарифмической линейке, - таким, 
что каждый шаг представляет собой сравнение длин. В случае вычислительной 
машины это приняло бы форму использования соответствующих (коллинеарных) 
пространственных координат, мантисс из двух таблиц логарифмов и осуществления 
"перевода" с помощью вычитания. Если взять более общий случай, то мы будем 
иметь дело с моделированием гармонической системы итерационного типа (подобной 
большинству коммерческих аналоговых машин) посредством решения описывающих ее 
дифференциальных уравнений. В то же время представление - или, грубо говоря, 
моделирование как конечного результата, так и внутреннего механизма процесса - 
потребовало бы моделирования каждой электронной компоненты (сопротивлений, 
конденсаторов, электрических контактов и т. д.), а также эффекта, производимого 
ими друг на друга, и, следовательно, их повторяющихся во времени изменений,
</P>
<P>
В последнем случае каждая аналоговая компонента оказывается как моделируемой, 
так и представляемой, но это отнюдь не всегда имеет место. Существуют 
аналоговые явления, не разложимые на отчетливо различимые части, например 
мыльная пленка, "вычисляющая" минимальную поверхность, ограниченную случайным 
образом изогнутой проволокой, не допускает представления типа описанного выше.
</P>
<P>
Правда, можно было бы сказать, что, поскольку мыльный пузырь (или любой  другой 
 материальный  объект)   состоит  из атомов, для  него в
</P>
<P class=Page>119</P>
<P>системой дифференциальных уравнений". В этом высказывании речь идет о 
физиологическом процессе, несомненно связанном с "переработкой информации", но 
никак не о самом информационном процессе.
</P>
<P>
Непонятно, на какой статус претендуют рассуждения Фодора: носят ли они 
априорный характер или предполагают эмпирическую основу? Иначе говоря, неясно, 
является ли вывод о том, что мозг работает на основе последовательно 
выполняемых элементарных операций, логическим следствием учета мозгом 
текстурных градиентов или нет. Пример, выбранный Фодором, менее всего 
способствует утверждению взгляда, что мозг или разум вообще выполняют 
какие-либо элементарные операции. Стало быть, мысль о необходимой связи между 
нахождением текстурных градиентов, процессом вычисления и последовательным 
выполнением операций - это просто его мнение. Правда, если окажется, что это 
рассуждение основано на смешении ряда понятий, сторонники психологического 
допущения всегда могут сменить платформу, заявив, что это отнюдь не априорная 
аргументация, а основанные на экспериментальных данных выводы,
</P>
<P>
В докладе, представленном Американской философской ассоциации, Фодор занял 
"априористскую" позицию, в то время как Дж. Миллер, Е.Галантер и К.Прибрам 
оправдывали свой подход ссылкой на имеющиеся, с их точки зрения, успехи в 
области моделирования процессов познания.
</P>
<P>
"Для организма план в основном представляет собой то же самое- что и программа 
для математической машины... Ньюэлл, Шоу и Саймон очень четко и систематично 
применяли иерархическую структуру перечней в своей работе над "языками для 
обработки информации", которые приме-
</P>
<P>
принципе всегда можно найти представление в виде необъятной (!) системы 
уравнений квантовой механики. Однако крайне сомнительно, что такая громада 
уравнений приведет хоть к какому-нибудь объяснению функционирования какого-либо 
объекта или, если речь идет о мозге, хоть к какой-нибудь связи с психологией. 
Если этих аргументов недостаточно, попробуйте представить себе обыкновенный 
арифмометр, состоящий из шестеренок и зубчатых передач; наша уверенность в том, 
что он работает в соответствии с законами механики и что любой содержательный 
аспект его функционирования допускает некоторое представление, ни в коей мере 
не связана с тем фактом, что он состоит из атомов. В самом деле, будь он 
изготовлен из какой-то таинственной неделимой субстанции, мы тем не менее были 
бы твердо уверены, что до тех пор, пока он функционирует посредством 
шестеренок, зубчатых передач и т. п., он остается некоторым механизмом и любое 
представление его в терминах шестеренок и зубчатых передач является его 
объяснением. То же самое, в сущности, касается и электронных аналоговых машин, 
и логарифмических линеек, и т. д.
</P>
<P>
Таким образом, принятие a priori положения, согласно которому для аналогового 
процесса всегда может быть найдено дискретное представление, совершенно 
неправомерно; оно заимствовано, так сказать, у правильного, но более слабого и 
не имеющего отношения к данному вопросу утверждения о простой моделируемости.
</P>
<P class=Page>120</P>
<P>няются при программировании для скоростных цифровых математических машин в 
случаях моделирования человеческих процессов мышления. Их успех е этом 
отношении, который, по нашему мнению, является очень значительным и 
многообещающим, подтверждает правильность гипотезы, что иерархическая структура 
является основной формой организации при решении задач человеком"  *.
</P>
<P>
В части I мы видели, что результаты работ Ньюэллэ, Шоу и Саймона далеко не 
впечатляющи, В чем же тогда состоят многообещающие экспериментальные 
подтверждения? Далее мы рассмотрим, на основании каких принципов оценивается 
работа А.Ньюэлла, Дж.Шоу и Г.Саймона.
</P>
<a name="24a">
<B><P>
I. Экспериментальные данные в пользу 
психологического допущения: 
критика научной методологии, 
используемой при моделировании процессов познания.
</P></B>
<P>
Попытка экспериментального оправдания психологического 
допущения ставит методологический вопрос о том, как оценивать 
экспериментальные данные. Простое сходство между поведением машин и людей не 
оправдывает психологического допущения, но существующая на сегодняшний день 
невозможность выявления деталей упомянутого сходства не оправдывает и отказ от 
этого допущения. Проверка психологического допущения требует тщательного 
сравнения отдельных шагов, посредством которых осуществляется обработка 
информации машиной и человеком. Как мы видели (гл. 1, разд. II), Ньюэлл, Шоу и 
Саймон откровенно отмечают черты сходства и различия между отчетами о поведении 
испытуемых при решении задач и результатами машинного моделирования процесса их 
решения. Посмотрим, как они оценивают полученные результаты.
</P>
<P>
А.Ньюэлл и Г.Саймон приходят к выводу, что их методы
</P>
<P>
"...дают общую схему для понимания механизмов поведения человека при решении 
задач. . они в конечном счете достаточно ясно показывают, что в основе 
свободного поведения мыслящего человека лежит сложный, но конечный и вполне 
определенный комплекс правил переработки информации"**.
</P>
<P>
Такой вывод на редкость ненаучен, так как Ньюэлл и Саймон признают, что их 
специфические теории - подобно любым научным теориям - должны приниматься или 
отвергаться на основе учета своей общности, то есть учета того круга явлений, 
которые их
</P>
<P>
* Дж. Миллер, Е. Талантер, К.Прибрам. Цит.соч., с. 30-31 (курсив мой. - 
Х.Д,) ,
</P>
<P>
** А. Ньюэлл и Г.Саймон. GPS - программа, моделирующая процесс 
человеческого мышления. - В кн.; Вычислительные машины и мышление, с. 301,
</P>
<P class=Page>121</P>
<P>программы в состоянии объяснить*. Но программы этих ученых не являются 
достаточно общими по крайней мере в трех отношениях. Имеющиеся данные касаются 
только таких наиболее благоприятных случаев, когда испытуемый может хотя бы 
частично дать отчет о своем поведении при "переработке информации" (игра, 
решение простых задач); случаи эти не включают распознавания образов, обучения 
естественному языку и его использования. Более того, даже в упомянутой 
ограниченной области результаты машинного моделирования соответствуют поведению 
индивидуума только после некоторой подстройки ad hoc. И наконец, даже это 
соответствие оказывается лишь частичным. Ньюэлл и Саймон отмечают, что их 
программа "обеспечивает полное объяснение поведения испытуемых при решении 
задач, хотя имеются пять исключений различной степени серьезности"**.
</P>
<P>
Исходя из этих ограничений и исключений, непонятно, каким образом Ньюэлл и 
Саймон могут претендовать на "общую структуру" и какую-либо научную 
интерпретацию соответствующих феноменов вообще. Дело здесь, по-видимому, в 
неправильном истолковании универсальности научных законов и теорий. Как 
известно, научные законы не допускают исключений; в данном же случае исключения 
признаются с откровенностью в надежде на то, что сам факт признания таковых 
компенсирует их важность. (Представим себе Галилея, утверждающего, что закон 
падающих тел справедлив для всех объектов, кроме пяти, относительно которых 
установлено, что они падают с иной скоростью.) Это не предполагает, разумеется, 
что наличие исключений обязательно дискредитирует научное положение. В науке 
существуют общепринятые способы преодоления такого рода трудностей. Для начала 
обобщение может быть выдвинуто как рабочая гипотеза, однако, пока не выяснены 
причины исключений, с провозглашением соответствующего научного закона следует 
повременить. Рабочая гипотеза не обязана объяснять все данные. Но, когда ученый 
претендует на создание научной теории - не говоря уже об "общей структуре 
понимания",- он обязан либо объяснить исключения на основе своей теории 
(подобно тому как отклонение от законов механического движения объясняется 
трением), либо предложить, в каком направлении искать объяснение, либо, 
наконец, исходя из своей теории, указать источник возникающих трудностей. 
Ньюэлл и Саймон, однако, не следуют ни по одному из этих путей.
</P>
<P>
На сказанное нами эти ученые могут возразить, что оснований для беспокойства 
нет, так как даже очень хорошие теории имеют
</P>
<P>
* A.Newell H.A.Simon. Computer Simulation of Human Thinking, p. 9.
</P>
<P>
** Ibid, p. 292.
</P>
<P class=Page>122</P>

</TD>
</TR>

</TABLE>

<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="0" WIDTH="80%">

<TR>
<TD>


<P>
исключения. Так, в своем исследовании научных революций Т.Кун отмечает наличие 
постоянных аномалий во всех нормально развивающихся областях естественных наук.
</P>
<P>
"Какие-то расхождения есть всегда. Даже наиболее неподатливые расхождения в 
конце концов приводятся обычно в соответствие с нормальной практикой научного 
исследования. Очень часто ученые предпочитают подождать, особенно если в других 
разделах данной области исследования есть много проблем, доступных для решения. 
Мы уже отметили, например, что в течение шестидесяти лет после исходных 
расчетов Ньютона предсказываемые сдвиги в перигее Луны составляли по величине 
только половину от наблюдаемых 61*.
</P>
<P>
Но это не может служить утешением для Ньюэлла и Саймона. Подобная терпимость к 
аномалиям возможна лишь в том случае если уже существует развивающаяся наука и 
"принимаемая   в качестве парадигмы теория должна казаться лучше, чем 
конкурирующие с ней другие теории"**, А это предполагает, что теория "работает" 
в совершенстве, по крайней мере в некоторой четко определенной области.   Но 
теорию познавательных процессов Ньюэлла и Саймона нельзя считать не только 
общей, но и вполне применимой к специально подобранному случаю. Именно там, где 
следует как будто ожидать полного соответствия, являющегося основанием для 
формирования парадигмы, мы находим исключения. Таким образом, хотя работа 
Ньюэлла и Саймона содержит несколько достойных внимания приближений, она не 
порождает знание, действенное в той мере, которая ей позволяет претендовать на 
открытие общих законов даже при наличии аномалий.
</P>
<P>
В своем рассуждении о "ньютоновской аномалии", вслед за отрывком, который мы 
процитировали выше, Т. Кун указывает, что "специалисты по математической физике 
в Европе продолжали безуспешно бороться с хорошо известным расхождением"***. 
Отсутствие подобного положения также невыгодно отличает работу Ньюэлла и 
Саймона от принятой научной практики. После того как исключении были 
установлены, никто из специалистов по моделированию процессов познания - и 
менее всего Ньюэлл и Саймон - не предпринял, судя по всему, даже попытки к их 
объяснению. Напротив, они продолжали практику своих грубых обобщений ad hoc, 
обращаясь к другим областям.
</P>
<P>
Существует и другой приемлемый способ обращения с исключениями. Если бы, исходя 
из независимых соображении, было установлено, что процессы мышления должны быть 
результатом последовательно выполняемых дискретных операций, определяемых 
некоторыми правилами, то в этом случае исключения
</P>
<P>* Т. Кун. Структура научных революций!, М., 1975, с. 110</P>
<P>** Там же, с. 36. </P>
<P>*** Там же, с, 111.</P>
<P class=Page>123</P>
<P>
можно было бы рассматривать либо как трудности случайного рода, связанные с 
методикой эксперимента, либо же как сомнительные случаи, которым предстоит дать 
объяснение на основе соответствующего закона. Только в этом случае специалисты 
в исследуемой области имели бы право считать каждую программу, моделирующую 
разумное поведение - независимо от степени приближения,- некоторым достижением, 
а все неудачи рассматривать как трудные случаи, требующие поиска более 
остроумных эвристик и программистской изобретательности. Однако тогда возникает 
проблема иного рода: как, исходя из независимых соображений, оправдать 
допущение о том, что человеческие "информационные процессы" носят дискретный 
характер? (В противном случае наличие исключений наряду с ограничениями в 
применении программ и отсутствием прогресса за последние 10 лет скорее служит 
опровержением, чем подтверждением упомянутой гипотезы.) Историю "оправдания" 
можно разделить на два этапа,
</P>
<P>
В своих ранних работах, не пытаясь оправдать важное - и спорное - допущение о 
дискретности, Ньюэлл и Саймон представляют его в качестве постулата или рабочей 
гипотезы, которая служит как бы путеводной нитью в их исследованиях. "Мы 
постулируем, что человеческое поведение управляется программой, 
организованной в виде ряда элементарных процессов переработки информации"*. 
Этот постулат, который сам по себе представляется достаточно спорным, в свою 
очередь выводится из такого основного методологического принципа, как принцип 
простоты. Согласно Ньюэллу и Саймону, этот принцип предписывает принимать в 
качестве предварительной наиболее простую гипотезу; в данном случае 
предварительная гипотеза состоит в том, что любой информационный процесс в 
некоторой степени напоминает процесс, реализуемый программно управляемой 
цифровой вычислительной машиной. Мы можем предположить, например, что при игре 
в шахматы, когда шахматист концентрирует внимание на определенной ситуации, 
сложившейся на шахматной доске, он подсознательно производит вычисления. Вообще 
говоря, если выданный машиной результат- машинная распечатка - содержит шаги, 
отсутствующие в отчете, который был дан испытуемым,- принцип простоты 
оправдывает в качестве руководства в проведении эксперимента простую рабочую 
гипотезу, гласящую, что соответствующие шаги были осуществлены человеком 
неосознанно. Дальнейшее исследование, разумеется, должно подтвердить эту 
гипотезу, в противном случае она в конце концов должна быть отвергнута.
</P>
<P>A.Newell, H.Simon. Computer Simulation of Human Thinking, p. 9,</P>
<P class=Page>124</P>
<P>Однако расхождения между отчетами испытуемых и результатами машинных 
экспериментов, равно как и трудности, возникающие при планировании, указывают, 
что дело обстоит гораздо сложнее, чем это получается, если следовать одному 
принципу простоты. В свете этого естественно было бы пересмотреть рабочую 
гипотезу - поступить аналогично тому, как поступила наука, покинувшая позиции 
Ньютоновой механики когда они оказались не в состоянии объяснить определенные 
явления; но именно здесь исследования в области моделирования процессов 
познания начинают идти в разрез с общепринятыми научными нормами. Подводя итог 
работам, проделанным в упомянутой области, Ньюэлл и Саймон заключают:
</P>
<P>
"Постоянно растущая масса данных свидетельствует о том, что элементарные 
процессы по переработке информации, происходящие в человеческом мозгу, в высшей 
степени напоминают некоторые из тех элементарных информационных процессов, 
которые включаются в системы команд, выполняемых современными вычислительными 
машинами"*.
</P>
<P>
Что же это за "растущая масса данных"? Разве были заполнены пробелы в 
протоколах или объяснены исключении? Вовсе нет. Видимо, "растущая масса 
данных"-это сами программы, программы, отсутствие у которых свойства 
универсальности могло бы, кажется, бросить тень сомнения на весь замысел, если 
бы не независимое от этих "данных" допущение о "цифровой" природе мозга. Для 
того чтобы - при наличии исключений - признать эти специфические программы 
законченными теориями, необходимо, чтобы психологическое допущение было 
предварительно обосновано независимо от них; между тем сегодня это допущение 
трактуется как гипотеза, которая подтверждается единственно успешной работой 
этих программ. Гипотезы, основанные на методологических принципах, которые в 
дальнейшем подтверждаются фактами, имеют право на существование. Однако в таких 
случаях недопустимо и совершенно непринято, чтобы гипотеза сама порождала те 
свидетельства, которые служат ее подтверждению.
</P>
<P>
Независимых эмпирических данных, свидетельствующих в пользу психологического 
допущения, не существует. А экспериментальный материал, который приводится в 
качестве подтверждения того факта, что разум работает подобно цифровой машине, 
свидетельствует о том, что это допущение, если только его не постулировать 
заранее, скорее всего, противоречит фактам.
</P>
<P>
Такого рода методологическая путаница свойственна в основном исследователям, 
работающим в области моделирования процессов  познания.  Однако и специалисты 
по "искусственному
</P>
<P>
* H.Simоп, A,Newell. Information Processing in Computer and Man.-American 
Scientist, vol. 52, 1964, September, p. 232.
</P>
<P class=Page>125</P>
<P>интеллекту" глубоко убеждены в плодотворности эвристического 
программирования; они также склонны думать, что все трудности носят случайный 
характер, а неудачи нисколько не свидетельствуют против применяемого 
экспериментального подхода. Основываясь на сравнительно небольшом круге задач, 
в которых их разработки привели к успеху, представители обоих направлений 
ничуть не сомневаются в том, что все еще не выясненные ими вопросы лежат в 
плоскости их исследований. Можно сказать, что все они держат себя так, как 
будто взятое ими в кредит психологическое допущение уже оплачено (хотя 
некоторые из них, а именно специалисты по моделированию процессов познания, 
пытаются представить этот "заем" как нечто второстепенное). Специалистам, 
работающим в этих областях, психологическое допущение представляется не 
гипотезой, которая может быть либо подтверждена, либо опровергнута опытом, а 
своего рода философской аксиомой, справедливость которой гарантирована а priori.
</P>
<a name="24b">
<B><P>II. Априорные аргументы в пользу психологического
допущении</P></B>
<P>
Априорный характер этой аксиомы ясно проявляется в том способе, каким Дж. 
Миллер, Е. Галантер и К.Прибрам вводят свою машинную модель. Процитированному 
нами выше (см.с.114) тексту, в котором утверждается, что успех Г.Саймона в 
значительной степени подтверждает точку зрения данных авторов, предшествуют 
слова, в которых они следующим образом определяют свои цели:
</P>
<P>
"Всякое полное описание поведения должно быть пригодным для того, чтобы служить 
перечнем инструкций, то есть оно должно обладать характерными чертами плана, 
который может руководить описываемым действием"*.
</P>
<P>
Дж. Миллер, Е. Галантер и К, Прибрам исходят из того, что само наше понятие 
объяснения или полного описания с неизбежностью предполагает, что поведение 
должно описываться в терминах перечня инструкций, то есть последовательности 
определенных реакций на определенные ситуации. Поэтому не удивительно, что 
такие психологи, как А.Ньюэлл, У.Ниссер и Дж. Миллер, считают работу по 
моделированию процессов познания многообещающей. С их точки зрения, если 
психология как наука вообще возможна, то она должна быть выразима в форме 
программ для вычислительных машин. Этот вывод следует не из эмпирических
</P>
<P>
* Дж, Миллер,   Е. Галантер  и   К.Прибрам,   Цит. соч., с. 30 (курсив мой. - 
Х.Д.).
</P>
<P class=Page>126</P>
<P>ценных, а вытекает из самого определения объяснения. Естестренно поэтому, 
что отклонения от протоколов экспериментов и всякого рода неудачи можно 
игнорировать. Сколь ни шатки экспериментальные результаты в области 
моделирования процессов познания, они должны быть первым шагом в направлении 
более адекватной теории.
</P>
<P>
Это определение объяснении требует дальнейшего анализа. Имеет ли оно смысл? 
Даже если ответ на этот вопрос положителен, можем ли мы предрешать результаты 
психологии, заранее предписывая ее теориям форму программ для вычислительных 
машин на том основании, что в противном случае психология вообще невозможна? А 
может быть, психология, понимаемая как моделирование процессов познания,- это 
тупик?
</P>
<P>
Начнем с утверждения о том, что всякое полное описание должно иметь форму 
перечня инструкций. Оно неясно. Рассмотрим поведение человека, которому 
предлагается выбрать из множества разноцветных геометрических фигур красный 
квадрат. Полное описание такого поведения, согласно Дж. Миллеру и его 
соавторам, должно представлять собой систему инструкций, то есть план, следуя 
которому испытуемый решает данную задачу. Какими же должны быть эти инструкции? 
Это могут быть самые общие правила такого рода: выслушай команду, посмотри на 
предметы, обрати внимание на их форму и выбери нужный предмет. Но какие более 
детальные инструкции следует дать, чтобы отличить квадрат от круга? Можно 
сказать: ''Подсчитай число сторон. Если их четыре, то это квадрат", А какие 
требуются инструкции для узнавания стороны? "Выбери наугад несколько точек и 
проверь, находятся ли они на кратчайшей линии, соединяющей концевые точки", и 
т.д. А как найти эти точки? Ведь в конце концов я воспринимаю геометрические 
фигуры, а не точки. Быть может, здесь наступает конец инструкциям и следует 
просто сказать: "Вы подсознательно воспринимаете точки, подсознательно 
обращаете на них внимание"? Но так ли это? И почему инструкции заканчиваются в 
этом пункте, а не раньше или позже? Если же инструкции такого рода вам все же 
кажутся приемлемыми, то какими инструкциями вы воспользуетесь, чтобы отличить 
красное от синего? На сей раз тем более неясно, почему и как полное описание 
должно в психологии даваться в виде ряда инструкций.
</P>
<P>
И все же такие утверждения имеют давнюю традицию. Кант в явной форме 
анализировал весь опыт и даже восприятие, перцепцию в терминах системы правил, 
а представление о том, что наши знания основаны на системе четких инструкций, 
восходит к еще более давним временам. Как мы видели, взгляд, согласно которому 
для понимания происходящего требуется полное описание,  состоящее  из  
последовательности  правил, восходит  к
</P>
<P class=Page>127</P>
<P>истокам философской мысли, то есть к тому времени, когда впервые были 
сформулированы наши представления о понимании и разуме. Платон, 
проанализировавший в "Эвтифроне" этот взгляд, спрашивает в "Меноне": необходимо 
ли добродетельному человеку руководствоваться точным знанием, доступным лишь 
философам? Иными словами, является ли "точное знание" необходимым условием для 
философского понимания действительности или же оно обязательно для 
добродетельного поведения любого человека? Вообще говоря, Платон расценивал 
навыки просто как средство для достижения прагматических целей. Поэтому он не 
сомневался в том, что точное знание не обязательно влечет за собой понимание 
(или реализацию) основанного на навыках поведения. Когда же речь идет о 
геометрических построениях или добродетельных поступках людей, то, по мысли 
Платона, даже не отдавая себе отчета о тех или иных правилах, люди тем не менее 
действуют на основе четкой рациональной структуры, выявление которой доступно 
философам. Далее Платон ставит вопрос, не следует ли скрыто человек, 
действующий как математик или носитель морального начала, подобного род 
программе, когда он поступает разумно.
</P>
<P>
В этом состоит решающий момент в истории развития концепций "понимания" и 
"объяснения".  Позиция самого Платона в; этом вопросе не оставляет никаких 
сомнений в том, что всякое разумное действие, то есть действие, не являющееся 
произвольным, имеет для него рациональную структуру, которая может быть 
выражена в терминах некоторой теории, и всякое лицо, предпринимающее подобное 
действие, непременно следует определенному набору правил, то есть некоторому 
знанию. Согласно Платону, это знание уже заложено в сознании человека, 
предопределено еще до его рождения и может быть выявлено с помощью 
вопросно-ответного  метода*.   Таким  образом, теория  человеческой 
деятельности, которая, по Платону, позволяет понять, что совершается на каждом 
этапе поведения человека, является для него также и объяснением того, как такое 
  поведение строится,1 Приняв такое представление о понимании и такое 
отождествление понимания и объяснения, мы с неизбежностью становимся на точку 
зрения сторонников моделирования процессов познания, которые нисколько не 
сомневаются в том, что полное описание поведения  представляет собой четкий 
набор инструкций для цифровой машины, а также в том, что эти правила в 
действительности могут быть использованы для составления программ машинного 
воспроизведения соответствующего поведения.
</P>
<P>
Мы уже рассмотрели предположение, согласно которому мышление есть 
вычисление**. Мы видели, что его притягательность
</P>
<P>*См.: Платон. Менон 82а - 8бв. Соч., т. 1, с 385-392, 
<P>** См."Введение", разд, I.</P>
<P class=Page>128</P>
<P>росходит еще к идее Платона о том, что наша жизнь в моральном отношении была 
бы гораздо более сносной, а наши знания более определенными, если бы они 
соответствовали истине. Правдоподобность этого предположения покоится, однако, 
просто на смешении механистических допущений, лежащих в основе успехов 
современных естественных наук, со своим коррелятом - формалистическим 
допущением о том, какой должна быть наука О человеческом поведении, если 
таковая возможна.
</P>
<P>
На определенном уровне это априорное допущение имеет смысл. Человек - это 
реальный объект. Успехи в области, естественных наук убедили нас в том, что 
полное описание поведения всякого реального объекта может быть выражено с 
помощью точных законов. Такое описание в свою очередь может, послужить созданию 
программ для вычислительных машин, которые, по крайней мере в принципе, в 
состоянии моделировать соответствующее поведение. Так родилась идея 
нейрофизиологического описания поведения человека в терминах "входов" (потоков 
энергии, физико-химических процессов мозга) и "выходов" (движений физических 
тел),- описания, которое в принципе допускает моделирование на цифровой 
вычислительной машине.
</P>
<P>
Такой уровень описания имеет смысл, по крайней мере в первом приближении. 
Соответствующая идея со времен Р.Декарта составляет часть общей физической 
картины вселенной. Безусловно, мозг - это орган, преобразующий энергию. Он 
улавливает входные сигналы, например изменение интенсивности освещения и 
связанные с ним изменения текстурных градиентов. Но, к великому сожалению 
психологов, физическое описание ни в коей мере не дает психологического 
объяснения, поскольку в нем отсутствуют какие бы то ни было психологические 
понятия. На этом уровне нельзя достаточно квалифицированно судить о таких 
сугубо человеческих факторах, как разум, мотивация, восприятие, память и даже 
цветовые и звуковые ощущения, в том плане, как это хотелось бы психологам. 
Энергия принимается и преобразуется - вот и весь сказ.
</P>
<P>
Разумеется, есть и другой уровень - назовем его феноменологическим, - на 
котором имеет смысл говорить о таких человеческих факторах, как 
целенаправленное действие, восприятие объектов и т. д. На этом уровне то, что 
мы видим,- это столы, стулья, другие люди; то, что мы слышим,- это звуки, иногда 
слова, предложения; то, что мы делаем,- это осмысленные действия в определенных 
осмысленных ситуациях. Но этот уровень устраивает психолога не более, чем 
физиологицеский, поскольку здесь нет ничего, что говорило бы о следовании 
инструкциям или правилам; психологическое объяснение - в том виде, который 
требуется для моделирования процессов познания, - здесь отсутствует. При 
столкновении с таким концептуальным кризисом
</P>
<P class=Page>129</P>
<P>психологи всегда стараются найти некоторый третий уровень - уровень, который 
был бы психологическим и в то же время давал бы объяснение поведению.
</P>
<P>
Для того чтобы психология могла претендовать на статус науки о человеческом 
поведении, она должна иметь предметом изучения человека, но человека не просто 
как физический объект, приходящий в движение, когда на него подается энергия 
(это задача физики и нейрофизиологии). Альтернатива состоит в том, чтобы 
попытаться изучить поведение человека как "входо-выходной" процесс- как 
совокупность определенного рода объектов-реакций в ответ на воздействие 
объектов некоего другого рода. Какого рода должны быть объекты на выходе и на 
входе, никогда не было ясно, но при всех обстоятельствах считалось, что для 
получения объяснения требуется представить себе человека в виде устройства, 
реагирующего на дискретные элементы по определенным законам. Последние могут 
быть похожи на закономерности причинно-следственного характера, описывая 
стереотипные схемы организма, взаимодействие которых с сигналами, поступающими 
из окружающей среды, обеспечивает сложные виды поведения. Устройство в данном 
случае - это "рефлекторный механизм", а законы являются законами формирования 
ассоциаций. Так мы приходим к эмпирической психологии Д.Юма и ее современному 
варианту - психологической теории, основанной на отношении "стимул - реакция" 
(S-R-психология) . Но предмет психологии может пониматься и иначе - как 
устройство по переработке информации, а законы могут трактоваться в рамках 
кантовской "модели" - как рассудок, составляющий правила разума, руководствуясь 
которыми последний отвечает на входные воздействия. В психологии эту школу 
называли "идеалистической", "интеллектуалистской" или "менталистской", теперь 
же к ней применяют термин "когнитивная психология".
</P>
<P>
До появления ЭВМ развитие эмпирической школы имело определенный предел, потому 
что с позиций "интеллектуализма" просто невозможно было расценивать человека 
как вычислимый объект. Но взгляд на субъект как на "трансцедентальное ego", 
применяющее правила, позволял относить научную теорию поведения к некоему 
"маленькому человечку" (гомункулу), пребывавшему в разуме и руководившему его 
действиями. Появление вычислительных машин, однако, вызвало непреодолимое 
желание трактовать действия в соответствии с правилами без привлечения 
"трансцедентального ego" или гомункула. Более того, представилась возможность 
программировать на вычислительных машинах модели, служащие для анализа даже 
таких форм поведения, как коммуникация на естественном языке, форм, которые, 
как представляется, слишком сложны для оценки их в терминах психологии "стимула 
и реакции". Словом, теперь есть устройство,
</P>
<P class=Page>130</P>
<P>которое может служить моделью для "менталистских" воззрений, и 
разочарованные бихевиоризмом психологи независимо от убедительности 
соответствующих аргументов или экспериментальных данных будут хвататься за эту 
столь "надежную" соломинку.
</P>
<P>
Вычислительная машина - это физический объект. Однако для описания работы 
машины нет необходимости вдаваться в рассуждения о колебаниях электронов, 
происходящих в ее транзисторах; описание производится на уровне организации ее 
двух-позиционных элементов - триггеров. И если психологам удастся 
интерпретировать организацию триггеров - а их срабатывание подчинено четким 
правилам - в терминах более высокого уровня, то их область исследований найдет 
наконец способ объяснения человеческого поведения.
</P>
<P>
Приманка, заключенная в описанном подходе, столь соблазнительна, что основной 
вопрос; допустимо ли на этом "третьем" уровне - промежуточном между физическим 
и феноменологическим уровнями - логичное, связное, понятное рассмотрение - даже 
не ставится. Но сигналы для тревоги налицо. Язык таких авторов, как Дж.Миллер и 
его соавторы, Ниссер или Дж.Фодор, непоследователен в буквальном смысле этого 
слова. Почти на каждой странице мы встречаем такого рода высказывания:
</P>
<P>
"Когда организм выполняет план, он делает это шаг за шагом, завершая одну его 
часть и затем переходя к следующей"*.
</P>
<P>
Здесь все три уровня представлены в неустойчивой и грамматически неправильной 
смеси. "Когда организм (биологический уровень.- Х-Д.) выполняет (машинная 
аналогия, заимствованная из человеческой деятельности, -Х.Д.) план, он 
(человеческий фактор. -Х.Д.)"63 и т. д. Можно "прокрутить" и наоборот: вместо 
персонифицированного организма ввести механизированный. Дж. Фодор говорит о 
"ментальной - мыслительной - переработке"**, или "ментальных операциях"***, 
так, как будто всем уже ясно, что это значит.
</P>
<P>* Дж.Миллер, У.Галэнтер, К. Прибрам. Цит. соч„ с. 32. Ср.</P>
<P>
следующие слова М.Минского в статье "Искусственный разум": "Эванс начал свою 
работу над задачей... с того, что сформулировал некую гипотезу о 
последовательности тех этапов или процессов, которые могли бы протекать в мозгу 
человека, когда он действует в такой же ситуации" (М. Минский. Искусственный 
разум.- В кн.: Информация, с. 205). К тому же М. Минский и С.Пейперт адресуют 
свою книгу "Персептроны" "психологам и биологам, которым хотелось бы знать, как 
мозг «вычисляет» мысли" (М. Минский, С.Пейперт. Персептроны, с. 7). В своей 
диссертации "Семантическая память" Р.Квиллиан говорит: "Понять значение - это 
не что иное, как найти, либо создать в мозгу того, кто понимает, некоторую 
конфигурацию символов" (R. Quilliаn. Semantic Memory. Bolt, Beranek and 
Newman, Inc., paper AFCRL-66-189, October 1966, p. 70).
</P>
<P>** J. Fodor. Psychological Explanation, p. 30.</P>
<P>*** Ibid, p. 22.</P>
<P class=Page>131</P>
<P>Если это смешение понятий у Дж. Миллера и его соавторов носит 
завуалированный характер, то у У.Ниссера и Дж.Фодора оно выступает совершенно 
отчетливо. Дело в том, что эти последние - в отличие от других специалистов, 
работающих в данной области,- стремятся выделить философскую основу своих 
исследований. Для уяснения того, в чем состоит упомянутое смешение, лучше всего 
четко представить себе нейрофизиологический и феноменологический уровни 
описания, а затем попытаться поместить между ними психологический уровень.
</P>
<P>
Определяя место уровня информационных процессов, У. Ниссро говорит:
</P>
<P>
"Безусловно, существует реальный мир, мир деревьев, людей, автомобилей и даже 
книг... Но у нас нет непосредственного доступа ни к этому миру, ни к 
какому-либо из его свойств"*.
</P>
<P>
Это, безусловно, верно, если речь идет о физических объектах**. Как определил 
Ниссер, "сенсорный вход - это не страница текста, а определенная конфигурация 
световых лучей"***. Все это так, но дальше Ниссер начинает смешивать физический 
и феноменологический уровни: "Лучи, сфокусированные должным образом линзой... 
попадают на чувствительную сетчатку, вызывав нервный процесс, который в конце 
концов приводит к способности видеть, читать и запоминать"****. Дело, однако, 
обстоит не так просто. Выражение "приводит к" двусмысленно, Световые волны, 
падая на ретину, приводят в конце концов к возникновению физико-химических 
процессов в мозгу, однако из этого вовсе не следует, что лучи света или 
нейронные процессы приводят к возникновению способности видеть****. Способность 
видеть - это не химический процесс и, следовательно, не может быть конечным 
результатом рода таких процессов. Если же выражение "приводит к" понимать как 
"необходимо и достаточно для, то
</P>
<P>
либо способность видеть и есть вся цепь явлений, приводящая к зрительному 
восприятию, либо это нечто совершенно отличное от самой цепи у любого из ее 
звеньев, И в обоих случаях не ясно, на каком основании Ниссер утверждает, что у 
нас нет непосредственного доступа к воспринимаемому миру.
</P>
<P>
Как только произведено это неправомерное объединение двух уровней - нейронного 
и феноменолргического - в единую струк-
</P>
<P>* U. Neisser. Op. сit, p. 3</P>
<P>** Разумеется, с феноменологической точки зрения мы имеем непосредственный 
доступ именно к объектам, а не к световые волнам.*** 
<P>*** U.Neisser. Op.cit., p.g.</P>
<P>**** Ibid. p. 3 </P>
<P>
***** По крайней мере если не считать себя сторонником теории тождества ощущений 
и мозговых процессов, а к таковым У.Ниссер, по-видимому, себя не пречисляет, 
ибо подобная позиция непременно потребовала бы некоторой дополнительной 
аргументации, отсутствующей у Ниссера.</P>
<P class=Page>132</P>
<P>туру, располагающуюся между личностью и миром, возникает необходимость 
создания нового словаря. Эта "ничейная" область описывается в терминах 
"сенсорных входов" и их "преобразований".
</P>
<P>
В данном употреблении термин познание относится ко всем процессам, посредством 
которых сенсорные входные данные преобразуются, сжимаются, обрабатываются, 
запоминаются, извлекаются из памяти и, наконец, используются... Такие термины, 
как ощущение, восприятие, воображение, впечатление, вспоминание, решение задач 
и мышление, наряду с многими другими относятся к гипотетическим стадиям или 
аспектам процесса познания"*.
</P>
<P>
Коль скоро вместо мира, в котором мы находимся, вводится понятие "сенсорного 
входа", "сенсорных входных данных", приходится допустить, что наше восприятие 
есть результат "развертывания" или "преобразования" этих "входных 
раздражителей"**. Но что означает такое преобразование, зависит от в высшей 
степени двусмысленного понятия "входного раздражителя". Если на вход действует 
энергия, то она с необходимостью преобразуется в какой-то иной вид энергии - 
вне всякого сомнения, процессы в мозгу материальны от начала и до конца. 
Вещественно-энергетические процессы могут преобразовываться, сжиматься, 
обрабатываться, накапливаться, извлекаться и использоваться, но при этом они 
всегда будут оставаться вещественно-энергетическими. Если, однако, раздражитель 
- это своего рода примитивное восприятие, элементарная перцепция, как, 
по-видимому, и считает У. Ниссер ("второй раздражитель оказывает некоторое 
влияние на восприятие непродолжительно действовавшего первого"***) , то нам 
следует выяснить, с какого рода "перцептом" мы в этом случае имеем дело. 
Философы больше не верят в "чувственные данные", и, если Ниссер вводит понятие 
"элементарного перцепта", он должен привести для этого немало аргументов и 
подкрепляющих фактов, В феноменологическом плане мы непосредственно 
воспринимаем физические объекты, воспринимаем, не отдавая себе отчета ни о 
чувственных данных, ни о световых лучах. Если Ниссер хочет перенести понятие 
входного воздействия из физической в перцептивную область, то ему следует 
объяснить, какого рода восприятие он имеет в виду и какими данными он 
располагает для доказательства того, что существует результат перцепции, 
который не является ни конфи-
</P>
<P>* U.Neisser. Op.cit, p. 4 (курсив мой.-Х.Д,).</P>
<P>
** Ibid., p. 5: "Наши знания о мире, - говорит здесь же Ниссер, должны 
быть каким-то образом извлечены из входных раздражителей". 
</P>
<P>*** Ibid., р. 22.</P>
<P class=Page>133</P>
<P>гурацией световых лучей, ни визуальным образом материального 
объекта*.</P>
<P>
Выход из положения, оказывается, заключается в использовании понятия 
"информации". "Информация" -говорит Ниссер,
</P>
<P>
* Возрождение юмовской концепции "данных органов чувств" неизбежно приводит 
исследователя к введению кантовских правил, служащих объяснению синтеза этих 
данных при переходе к восприятию объектов. Было бы более естественно и потому 
более целесообразно с точки зрения определения направления дальнейших 
исследований выяснить, что же именно делают такие психологи, как У.Ниссер, 
независимо от ошибочности вводимых ими понятий. Такого рода работа предполагает 
попытку определения тех скрытых ориентиров в перцептивном поле, которые 
оказываются существенными в различных областях восприятия, например тех, 
которые играют важную роль в восприятии глубины. Вопрос о том, какие именно 
неявные ориентиры необходимы, можно решить посредством систематического 
исключения различных факторов, таких, как бинокулярное зрение, смещение, 
текстурный градиент, и т. д. Можно даже определить порядок зависимости и 
количество этих скрытых ориентиров, которые являются существенными в данный 
момент. В результате, как надеются сторонники этого направления, будут выявлены 
последовательные шаги, соответствующая компоновка которых позволит разработать 
структурную схему программы для ЭВМ. Если это удастся, то появится возможность 
формализовать законы, по которым на каждом этапе вход преобразуется в выход.
</P>
<P>
Для работы такого рода нет необходимости прибегать к "подсознательным 
правилам", конституирующим воспринимаемое целое из некоторых составляющих 
элементов. В этом случае мы уже никогда не скажем, что "у нас нет 
непосредственного доступа ни к этому миру, ни к какому-либо из его свойств". 
Психологически реальными в подобной теории будут не элементы и правила, а как 
раз те самые, используемые в нашем обычном восприятии объектов, скрытые 
ориентиры, которые и важны для теории.
</P>
<P>
Хотя в большинстве случаев мы не отдаем себе отчета в их существовании, эти 
скрытые ориентиры отнюдь не неосознаваемы. Фокусируя на них внимание, мы в 
состоянии осознать их - в отличие от событий на нейронном уровне или даже от 
тех "моментальных снимков" объектов, которые, по утверждению Ниссера, мы 
действительно воспринимаем. Иногда эти ориентиры до такой степени неуловимы, 
что мы не можем обнаружить их при простом рассматривании. Так, например, 
невозможно уловить незначительные смещения каждой точки на картинке Джулеза, 
благодаря которым возникает иллюзия глубины. Но если бы нам сказали, на что 
следует обратить внимание, то с помощью подходящего измерительного устройства 
мы смогли бы, скорее всего, обнаружить эти смещения. Таким образом, можно 
сказать, что эти неявные ориентиры реально существуют с психологической точки 
зрения, то есть в том смысле, что мы можем их осознать.
</P>
<P>
"Структурная схема" тоже реальна с психологической точки зрения, но лишь в тех 
узких рамках, когда она выражает порядок зависимости неявных ориентиров. Нет 
никакого сомнения в том, что существует какое-то весьма приблизительное 
соответствие между структурной схемой, о которой идет речь, и протекающими в 
мозгу физическими процессами, но даже в этих случаях нет оснований говорить о 
такой подсознательной переработке, как если бы мозг представлял собой цифровую 
вычислительную машину, работающую по некоторой программе.
</P>
<P>
Любопытно, что, когда психологи действительно проводят подобного рода 
исследования, они обнаруживают, что отдельных ориентиров, которые
</P>
<P class=Page>134</P>
<P>- вот  что  преобразуется, и наша цель- понять структурную 
картину этого преобразования"*. Но поскольку понятие входного раздражителя 
осталось неоднозначным, мы так и не знаем, что это за информация и как 
предполагается соотнести ее с "входным раздражителем", который может быть либо 
энергией, либо непосредственно восприятием.
</P>
<P>
И наконец, смешение этих двух взаимозависимых и неоднозначных   понятий - 
"входной  раздражитель"  и  "информация"-	проявляется особенно отчетливо в 
"основной мысли" книгиУ. Ниссера:
</P>
<P>
"Основная мысль состоит в тоги, что способность видеть, слышать и запоминать- 
все это конструктивные акты, в которых в зависимости от обстоятельств в большей 
или меньшей степени используется информация (Src. - Х.Д.), содержащаяся в 
раздражителе. Мы полагаем, что эти конструктивные процессы проходят в два 
этапа. Первый носит предварительный характер; на кем происходит охват явления в 
целом; имеет место грубая обработка информации, процесс "запараллелен". На 
втором этапе переработка информации осуществляется последовательно; происходит 
обдуманный, тщательный, требующий внимания процесс конструирования"**.
</P>
<P>
Неоднозначность представления о "входной информации" и связанную с этим 
логическую гетерогенность той системы понятий, которая лежит в основе этого 
подхода и его следствий, легче всего продемонстрировать на конкретном примере. 
Посмотрим, как У.Ниссер анализирует восприятие страницы текста.
</P>
<P>
"Мы воспринимаем движущиеся объекты как цельные вещи. Эту способность можно 
объяснить только тем, что восприятие является результатом интегративного 
процесса, развертывающегося во времени. Тот же процесс, безусловно, лежит в 
основе построения визуальных объектов на основе   последовательности     
моментальных снимков, производимых движущимся глазом"***.
</P>
<P>
Здесь следует задать вопрос: Что это за "моментальные снимки"? Конфигурации 
распределения энергии? Или мгновенные картины страницы? Если это конфигурации 
распределения энер-
</P>
<P>
были бы достаточны и необходимы, не существует, однако различные их комбинации 
оказываются достаточными при некоторых конкретных ограничениях. Порядок 
зависимости неявных ориентиров также меняется от ситуации к ситуации. Поэтому 
получающиеся при этом результаты могут быть истолкованы как структурная схема 
лишь в очень редких случаях и только в очень ограниченном смысле. Для того 
чтобы полностью формализовать свою теорию в терминах машинных моделей, 
экспериментаторам пришлось бы либо определить вход с помощью абстрактных, не 
зависящих от ситуации переменных, либо отыскать метаправила, по которым 
распознаются конкретные ситуации и устанавливается соответствие между этими 
ситуациями и конкретным порядком зависимости. До сих пор не удалось обнаружить 
ни таких абстрактных переменных, ни таких правил, (См. мою статью Phenomenology 
and Mechanisms, In: NOUS, vol- V, No, I, February, 1971.  
</P>
<P>* U. Neisser. Op. cit., p. 8.</P>
<P>** Ibid., p. 10,</P>
<P>*** Ibid., p. 140.</P>
<P class=Page>135</P>
<P>гии, то не имеет смысла говорить, что они воспринимаются; их интеграция 
производится не воспринимающим субъектом, а мозгом как физическим объектом. В 
то же время на феноменологическом уровне вообще нет надобности интегрировать 
отдельные "моментальные снимки" страницы. Последняя воспринимается постоянно, а 
представление о том, что она зрительно дается в форме последовательности 
"моментальных снимков" или "входных раздражителей",- это уже результат 
абстракции от этой непрерывно наличествующей страницы. Разумеется, зрительная 
фиксация страницы связана с некоторой "переработкой", но с переработкой не 
результатов первичного восприятия объектов, или "моментальных снимков" - что 
может только привести к вопросу о принципах их собственной "конструкции", - а с 
переработкой некоторых меняющихся форм распределения энергии, воздействующей на 
глаз.
</P>
<P>
Смешение понятий, явившееся результатом попытки введения промежуточного уровня 
рассмотрения между физиологическим и феноменологическим, еще более отчетливо 
выражено в работе Дж. Фодора, которая не оставляет сомнений относительно 
позиции ее автора по данному вопросу. Обсуждая восприятие зрительных и слуховых 
образов, Фодор отмечает: "Представление о лице, мелодии или форме, которым вы 
располагаете... включает описание формальной структуры, относящейся к 
соответствующей области, и акт распознавания построен на использовании такого 
рода информации для интеграции текущих сенсорных входов"*.
</P>
<P>
И опять возникает вопрос, что значит "сенсорный вход". Если "сенсорный вход" - 
это сразу или лицо, или мелодия, или форма, то все уже сделано. Если же, 
напротив, "сенсорный вход" - это физическая энергия, воздействующая на органы 
чувств, то невозможно понять, что имеет в виду Фодор, говоря об "использовании" 
"представления" или "информации" для интеграции таких "входов", поскольку 
интеграция в применении к физической энергии является, несомненно, процессом 
дальнейшего энергетического преобразования.
</P>
<P>
Разумеется, если считать этот спорный вопрос решенным и согласиться с тем, что 
мозг - это цифровая машина, то идея, согласно которой понятие, или "концепт",- 
это формальная структура для организации данных, приобретет некоторый смысл. В 
этом случае "сенсорный вход" не будет трактоваться ни как результат восприятия, 
ни как форма распределения энергии - это будет последовательность квантов 
информации, а понятие, "концепт", будет представлять собой систему инструкций 
для соотнесения этих квантов с ранее накопленными данными и опознавания 
результата. Но это равноценно гипотезе о том, что человеческое поведение может 
быть понято на основе аналогии с цифровой
</P>
<P>* J. Fоdоr. Psychological Explanation, p, 26.</P>
<P class=Page>136</P>
<P>машиной. Для подтверждения этой гипотезы потребуется создание теории, 
объясняющей, чем являются эти "кванты", и опирающейся на экспериментальный 
материал-
</P>
<P>
Но Дж. Фодор, равно как и Дж. Миллер и его соавтора, считает, что представление 
о "сенсорном входе" и "концепте" как о правиле организации этого "входа" не 
требует никаких оправданий. Оно содержится в самом понятии психологического 
объяснения.
</P>
<P>
"Психологическая теория - в той мере, в какой это касается поведения, - может 
рассматриваться как функция, отображающая конечное множество входных 
воздействий на организм в бесконечное множество возможных выходных реакций"*.
</P>
<P>
В качестве концептуального представления отношений, имеющих место между 
восприятием и поведением, - представления, которое нам предлагают принять вне 
зависимости от экспериментальных сведений о работе мозга, - такое описание 
просто непостижимо.
</P>
<P>
Как и в случае с У.Ниссером, непоследовательность этого анализа лучше всего 
видна на конкретном примере. Дж.Фодор пытается выяснить, каким образом "мы 
можем воспринимать как сходное" - речь идет о мелодии - "то, что с физической 
точки зрения представляет собой совершенно различные последовательности тонов" 
(музыкальных звуков)**. Анализ такого рода не может не вызвать многочисленных 
вопросов; понимаются ли последовательности тонов в физическом или 
феноменологическом смысле? Что это - структуры, состоящие из звуковых волн или 
же из "перцептов"? Замечание о физическом различии тонов предполагает, видимо, 
первое. И в самом деле, на уровне вещественно-энергетических процессов 
несомненно, что входная энергия различных частот коррелирует с перцептивными 
состояниями. Происходящие при этом преобразования энергии, видимо, будут 
когда-то открыты нейрофизиологами. Но такие физические последовательности тонов 
нельзя "услышать" - мы не можем слышать частот; мы слышим только звуки и потому 
a fortiori частоты не могут быть "слышимы, воспринимаемы как сходное". Если же 
мы в то же время будем трактовать входной сигнал как последовательность тонов в 
феноменологическом смысле, где уже можно предположить, что мы "слышим нечто как 
сходное", то мы окажемся на уровне восприятия и, к несчастью для Фодора, вопрос 
о том, каким образом эти последовательности тонов наш слух воспринимает как 
одинаковые, снимается. Ибо для того чтобы корректно сформулировать эту 
проблему, надо в первую очередь исходить из уже известного нам факта, что в 
феноменоло-
</P>
<P>* Ibid., p. 29, <P>** Ibid., р. 26.</P>
<P class=Page>137</P>
<P>гическом смысле последовательности тонов воспринимаются одинаково. На 
феноменологическом уровне мы слышим их одинаково, потому что они звучат 
одинаково.
</P>
<P>
Подходя к этому вопросу с другой стороны, Дж. Фодор задает вопрос: "Какую 
конкретно ноту (то есть в каком ключе, при каких абсолютных значениях 
длительности, насыщенности, ударности, высоты тона и силы звучания) мы ожидаем 
услышать после того, как прослушали первые несколько нот песни Лилибурлеро64*.  
 Но   мы   "ожидаем"   новее   не   каких-то "абсолютных значений". Мы ожидаем 
услышать мелодию. Абсолютные значения составляют проблему для нейрофизиолога, 
вооруженного осциллографом, или для того, кто хочет слышать отдельные ноты, но 
не для человека, воспринимающего мелодию. Если бы мы в действительности 
воспринимали эти "абсолютные значения", то для объяснения того, как мы узнаем в 
различных последовательностях тонов одну и ту же мелодию, нам действительно 
пришлось бы стать на позицию "последовательного концептуализма", которую 
защищает Фодор.
</P>
<P>
"Весьма трудно объяснить способность к распознаванию типа объектов, несмотря на 
большое различие в их признаках, если не принять тот факт, что при 
распознавании используются чрезвычайно абстрактные понятия. Но и в этом случае 
трудно объяснить ... способ применения этих понятий, если не допустить 
возможности участия психологических механизмов исключительной сложности"**.
</P>
<P>
Здесь налицо путаница в использовании слов "тип" и "признак". Что это за 
признаки? Воспринимаемая в феноменологическом смысле последовательность звуков 
(мелодия) не может быть абстракцией (типом), по отношению к которой входные 
потоки физической энергии являются конкретизацией (признаками) . Восприятие и 
физическая энергия в равной степени являются конкретными явлениями, но они 
совершенно разного рода. Никакие ухищрения не приведут к устранению разрыва 
между колебаниями энергии на входе и длительным восприятием звучания. Одно не 
является конкретизацией другого. Но в равной степени нельзя считать, что 
признаки - это феноменологические последовательности изолированных абсолютных 
тонов (в том смысле, как это понимают сторонники теории "чувственных данных"). 
Слушая мелодию, мы не воспринимаем абсолютных тонов, поэтому в данной 
интерпретации не должно быть места ни для каких признаков.
</P>
<P>
Но даже если предположить, что Дж. Фодор имеет в виду физическую модель, 
которую можно вложить в вычислительную машину, то данный  вид распознавания 
образов можно осу-
</P>
<P>* Ibid, p. 2a <P>** Ibid.</P>
<P class=Page>138</P>
<P>ществить, скажем, с помощью нейронной сети или аналогового устройства, если, 
разумеется, это возможно в принципе. Нет никаких оснований полагать, что такую 
модель можно реализовать с помощью эвристической программы (системы абстрактных 
понятий), не говоря уже о том, нужна ли вообще такая программа в концептуальном 
плане.
</P>
<P>
И все же Фодор никогда не ставит под вопрос допущение, согласно которому 
существует некоторый уровень переработки информации, при котором процесс 
преобразования энергии может рассматриваться в терминах последовательности 
определенных операций. Единственно, что его интересует, это: "Как можно 
установить, что машина руководствуется той же программой, что и мы, то есть 
выполняет те же операции?" Так, например, поставив вопрос, как определить, 
удачна ли оказалась некоторая машинная модель, Фодор говорит: "Нам следует лишь 
принять соглашение, что формы поведения выделяются не только в соответствии с 
внешне наблюдаемыми реакциями организма, но также и на основе учета той 
последовательности мыслительных (ментальных) операций, которая лежит в основе 
этих внешних реакций"*.
</P>
<P>
Или еще яснее:
</P>
<P>
"Сильная эквивалентность требует, чтобы операции, на которых основано поведение 
машины, были того же типа, что и операции, лежащие в основе поведения 
организма"**
</P>
<P>
Здесь следует принять во внимание, что аргументация Дж. Фодора зависит от 
двоякого рода допущений- Во-первых, подобно Дж. Миллеру и его соавторам, а 
также У.Ниссеру, Дж»Фодор использует неоднозначное понятие "входа", "входного 
раздражителя", "входного стимула". Оно позволяет ему ввести такой уровень 
рассмотрения, на котором представляется возможным строить анализ перцепции так, 
как если бы человек был машиной, на вход которой подаются данные, называемые 
"информацией, содержащейся в раздражителе". Это равносильно другому допущению - 
о том, что, помимо энергетических преобразований, "в процессе восприятия 
происходит переработка данных"***.
</P>
<P>
Далее Дж, Фодор делает два допущения иного рода - допущения, которые он, 
по-видимому, не вполне осознает; 1) что "данные" обрабатываются подобно тому, 
как это делается на цифровой машине, то есть с помощью дискретно выполняемых 
операций, и 2) что работа этой цифровой машины носит последовательный   
характер   и   направляется   чем-то  вроде  эвристической
</P>
<P>* Ibid., p. 140  .</P>
<P>** Ibid., p. 141.</P>
<P>*** Ibid., p. 83.</P>
<P class=Page>139</P>
<P>программы, в силу чего можно говорить о некоторой последовательности такого 
рода операций. Защищая идею "последовательного концептуализма", согласно 
которой процесс восприятия требует сложных мыслительных операций, Фодор таким 
образом догматически вводит представление о "процессе переработки информации", 
оставляя без внимания вопрос об иных формах вычислительных устройств и даже 
иных формах цифровой обработки данных. Вот какими словами завершает Дж.Фодор 
свой анализ явления распознавания мелодии:
</P>
<P>
 Отличительным признаком этого явлении оказывается выделение "инвариантов", то 
есть факторов, приводящих восприятие к радикальному и постоянному отбрасыванию 
информации, непосредственно содержащейся в физическом входном воздействии. 
Такие факторы со времен Г. Гельмгольца считаются лучшим аргументом в пользу 
существования неосознаваемых мыслительных операций. Если мы хотим объяснить 
несоответствие между входным воздействием и результатом восприятия, то другой 
альтернативы не существует"*.
</P>
<P>
Свое рассмотрение логики машинного моделирования Дж.Фодор строит на основе 
непоколебимого доверия к этим шатким допущениям. Легкость, с которой эти 
лжеаргументы сходят за концептуальный анализ, показывает, сколь сильны тиски 
платоновской традиции и сколь необходима вера в "уровень информационных 
процессов", который должен существовать, если психология возможна как наука65.
</P>
<P>
Безусловно, использование вычислительных машин в качестве модели правомерно при 
условии, что мы отдаем себе отчет в том, что имеем дело только с гипотезой. Но 
в работах Дж.Миллера и его соавторов, У.Ниссера и Дж.Фодора, как мы видели, эта 
гипотеза преподносится как априорная истина, то есть как результат глубокого 
концептуального анализа процесса поведения человека.
</P>
<P>
Правда, время от времени нам удается мельком увидеть эмпирическую основу 
данного допущения. Аргументы Дж.Фодора в пользу правомерности использования 
машинно-математических моделей в психологии полностью покоятся на 
гипотетическом представлении о том, что "мы располагаем машиной, 
удовлетворяющей любым экспериментальным тестам, которые можно придумать для 
проверки соответствия всех форм поведения машины, с одной стороны, и организма 
- с другой"**. Однако эмпирический характер этого утверждения, выраженный в 
столь завуалированной форме, опровергается уже тем, что оно построено в 
терминах "последовательности мыслительных операций", как будто заранее 
известно, что машина, о которой идет речь, возможна.
</P>
<P>*Ibid, p. 85 </P>
<P>** Ibid,, p. 146.</P>
<P class=Page>140</P>
<P>Только в том случае, если машина, о которой говорит Дж.Фодор, существует и 
действительно работает по принципу последовательного выполнения операций, для 
постановки и интерпретации экспериментов в психологии правомерно использовать 
понятия, относящиеся к цифровому вычислительному устройству, управляемому 
эвристической программой. Но чтобы решить вопрос о возможности такой разумной 
машины, и, соответственно, о правомерности данной системы понятий, необходимо 
для начала попытаться запрограммировать такую машину или оценить уже испытанные 
программы. Если же "машинный язык" используется как самоочевидное и бесспорное 
средство для формулировки той системы понятий и представлений, в терминах 
которой должны ставиться эксперименты и пониматься их результаты, и если при 
этом не выдвигается аргументов, значимых a priori, и не предлагается 
экспериментального доказательства существования упомянутой машины, то ни к 
чему, кроме путаницы, мы не придем.
</P>
<P>ЗАКЛЮЧЕНИЕ</P>
<P>
Итак, мы снова движемся по замкнутому кругу. В конце разд. I этой главы мы 
видели, что множество исключений, не получивших объяснения, и отсутствие 
моделей процессов более высоких порядков, таких как сосредоточение внимания и 
различение существенного и несущественного, ставят под сомнение соответствующие 
экспериментальные результаты. Последние можно считать многообещающими, только 
приняв априорное допущение, согласно которому наш разум должен работать подобно 
цифровой машине, управляемой эвристической программой. Но сейчас мы видели,-что 
лишь достаточно обоснованные аргументы в пользу того, что разум функционирует 
подобно вычислительной машине, могут свидетельствовать о действительном или 
потенциальном существовании такого рода разумной машины.
</P>
<P>
Ответ на вопрос, может ли человек создать подобную машину, должен основываться 
на уже проведенной работе. Учитывая то, что было сделано ранее, и тот застой, 
который наблюдается на сегодняшний день, наиболее правдоподобным представляется 
отрицательный ответ; "Нет". Невозможно обрабатывать недифференцированный 
"входной сигнал", не проводя различия между существенными и несущественными, 
важными и маловажными данными. Мы видели, что А.Ньюэллу, Дж.Шоу и Г.Саймону 
удалось избежать этой проблемы лишь путем предварительной обработки данных и 
что Дж. Миллер и его соавторы избежали ее только потому, что ошибочно полагали, 
будто Ньюэлл, Шоу и Саймон уже располагают программой для выполнения этого
</P>
<P class=Page>141</P>
<P>первоначального отбора. Но коль скоро такие многообещающие эмпирические 
результаты отсутствуют, то и все эти сами себя подтверждающие аргументы 
разваливаются как карточный домик.
</P>
<P>
Единственный способ справиться с феноменом избирательности состоит в 
использовании процедур аналогового характера, соответствующих избирательной 
способности наших органов чувств. Но тогда процесс в целом не будет более 
цифровым, и у нас, естественно, возникает вопрос, ограничивается ли типичный 
аналоговый процесс только периферическими органами. Все это бросает тень 
сомнения на идею "последовательно выполняемых операций" и возвращает нас к 
началу дискуссии. Затруднения такого рода означают, что хотя человек - это, 
безусловно, физический объект, перерабатывающий физические входные сигналы по 
законам физики и химии, может оказаться, что человеческое поведение необъяснимо 
в терминах информационного процесса, состоящего в получении и обработке 
дискретных входных сигналов. Более того, ни из физики, ни из результатов 
опытного характера отнюдь не следует, что действия человека следует объяснять 
именно таким способом, поскольку на физическом уровне мы имеем дело с 
непрерывно меняющимися формами энергии, а на феноменологическом - с объектами 
уже организованной области опыта.
</P>
<P>
Изучение этой области опыта и должно составить альтернативу для психологии в 
качестве возможной сферы ее исследований. Но прежде чем перейти к рассмотрению 
этой альтернативной теории (часть III), мы должны рассмотреть два других 
допущения - допущения, которые если и не укрепляют направление "моделирования 
процессов познания", тем не менее, по крайней мере на первый взгляд, дают 
надежду на успех в области "искусственного интеллекта".
</P>

<HR>
<center>
<A href="ch3.htm#25">К главе 5</A>
</center>

</TD>
</TR>

</TABLE>
<center>

</BODY>
</HTML>
